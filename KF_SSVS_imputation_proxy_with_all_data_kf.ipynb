{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zboraon/proxy_impuation_SSVS/blob/main/KF_SSVS_imputation_proxy_with_all_data_kf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbhLbYoM-xPq"
      },
      "source": [
        "# Necessary libraries\n",
        "\n",
        "I recommend the users to use this specific model on Colab, or a Debian based distro. If you want to apply the same model on a different data set, you have to know how to install jags (https://sourceforge.net/projects/mcmc-jags/) and specific R packages to your computer.\n",
        "\n",
        "Install and load the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7On6vFPi-Z2A"
      },
      "outputs": [],
      "source": [
        "system(\"apt install -y jags\")\n",
        "system(\"apt install -y r-base\")\n",
        "\n",
        "# system(\"apt install fonts-lmodern\")\n",
        "# system(\"apt install lmodern\")\n",
        "# system(\"apt install -y libcairo2-dev\") # For Cairo graphics library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yjiJGhBk9jyU"
      },
      "outputs": [],
      "source": [
        "if (!require(\"runjags\")) install.packages(\"runjags\")\n",
        "if (!require(\"RCurl\")) install.packages(\"RCurl\")\n",
        "if (!require(\"bayesplot\")) install.packages(\"bayesplot\")\n",
        "if (!require(\"patchwork\")) install.packages(\"patchwork\")\n",
        "if (!require(\"zip\")) install.packages(\"zip\")\n",
        "\n",
        "#install.packages(\"extrafont\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqH5QS0q0HcU"
      },
      "outputs": [],
      "source": [
        "library(RCurl)\n",
        "library(runjags)\n",
        "library(coda)\n",
        "library(parallel)\n",
        "\n",
        "# for plots\n",
        "library(bayesplot)\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(patchwork)\n",
        "\n",
        "# for saving\n",
        "library(zip)\n",
        "\n",
        "#library(extrafont)\n",
        "\n",
        "# Import fonts, including 'lmodern' if available\n",
        "#font_import(paths = NULL, prompt = FALSE)\n",
        "#loadfonts(device = \"pdf\")\n",
        "\n",
        "#font_import(pattern = \"lmsans*\", prompt = FALSE)\n",
        "#loadfonts()\n",
        "#par(family = \"LM Sans 10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apmCTePo_enT"
      },
      "source": [
        "# Preliminary data definitions\n",
        "Predefine intervals, data, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9akVtlyq_lZd"
      },
      "outputs": [],
      "source": [
        "# Filter the data for a specific time range\n",
        "# Is your regression \"forwards\" or \"backwards\" in time?\n",
        "# For example, if the interval to be imputed is 0--10 ka BP,\n",
        "# and there is data between 10--50 ka BP, your approach is \"forwards\".\n",
        "# You approach the missing inteval from 50 ka BP to the 10 ka BP. Otherwise,\n",
        "# your approach is backwards.\n",
        "timescale = \"forwards\"\n",
        "\n",
        "# For the upper explanation, your whole interval is time_range <- c(50,0)\n",
        "time_range <- c(624, 478) # choose the time interval for your whole regression\n",
        "# c(335, 196) #c(533, 381)#c(381,533) #c(132, 1) #c(132, 1)\n",
        "# c(80, 132) #c(624, 380)# c(80, 218) # c(80, 196) c(218, 132)\n",
        "\n",
        "# temporal length for forecast. the final time point minus this value\n",
        "# should correspond to the length of the data to be imputed\n",
        "# for the upper example, 10-0+1=11, i.e. kyrs_to_forecast <- 11\n",
        "kyrs_to_forecast <- 61\n",
        "\n",
        "\n",
        "# resolution of the state-space model, depends on your choice. In this application,\n",
        "# I chose it to be 1kyrs\n",
        "resolution <- 1\n",
        "\n",
        "# data with missing values. this name must be the same with the data\n",
        "# that is used in the jags model. this code handles it for Ohrid data.\n",
        "data_to_forecast <- \"O18\" #\"O18\"C13\n",
        "\n",
        "# Specify the time points where you want to interpolate\n",
        "# Adjust the time sequences based on the timescale\n",
        "if (timescale == \"forwards\") {\n",
        "  new_time <- seq(time_range[1], time_range[2], by = -1 * resolution)\n",
        "  new_time_shrt <- seq(time_range[1], time_range[2] + kyrs_to_forecast, by = -1 * resolution)\n",
        "} else {\n",
        "  new_time <- seq(time_range[1], time_range[2], by = resolution)\n",
        "  new_time_shrt <- seq(time_range[1], time_range[2] - kyrs_to_forecast, by = resolution)\n",
        "}\n",
        "\n",
        "# the names of the covariates, as in the data to forecast\n",
        "covariatenames <- c(\"AP\", \"MS\", \"Qz\", \"TIC\", \"TOC\", \"TN\", \"TS\", \"Clay\", \"bSiO2\", \"Ca\", \"K\", \"Fe\", \"Zr\")\n",
        "\n",
        "# type of the model,\n",
        "kf_model <- \"onlyageerror\"  # Modify as needed for different models: \"noerror\", \"eiv\" \"fullstochastic\" \"onlyageerror\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NajHZIzzANp"
      },
      "source": [
        "# Select your regression model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMZG8wNly9k5"
      },
      "outputs": [],
      "source": [
        "# this is to specify if your regression model is a regression model with\n",
        "# AR(1), random walk level, static level, or a simple regression\n",
        "# The models other than simplyssvs are not suitable due to the increased variance\n",
        "# at forecasts, and they are against the logic of simply building the data with\n",
        "# the rest of the data. In case you want to use them, uncomment the lines and\n",
        "# if needed make necessary appropriate changes. I did not make the last changes\n",
        "# on them. I am not sure if they are working.\n",
        "mymodel <- \"simplyssvs\" # model = c(\"simplyssvs\", \"rwlevel\", \"staticlevel\", \"ar1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRkRrfO11SW-"
      },
      "source": [
        "# Read Ohrid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaYqwYRr1T-1"
      },
      "outputs": [],
      "source": [
        "# Read data\n",
        "ohrid_geochem_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_geochemistry.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "ohrid_MS_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_MS.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "ohrid_XRF_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_XRF.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "ohrid_pollen_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_pollen.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "\n",
        "ohrid_age_depth_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_agedepth.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "\n",
        "ohrid_XRF_data_francke_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_XRF_franckeetal16.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "\n",
        "ohrid_sediment_data_francke_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/main/Data/\",\n",
        "  \"Lake_Ohrid/Ohrid_sediment_franckeetal16.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "\n",
        "ohrid_geochem_url <- getURL(ohrid_geochem_data_url_text)\n",
        "ohrid_ms_url <- getURL(ohrid_MS_data_url_text)\n",
        "ohrid_xrf_url <- getURL(ohrid_XRF_data_url_text)\n",
        "ohrid_pollen_url <- getURL(ohrid_pollen_data_url_text)\n",
        "ohrid_agedepth_url <- getURL(ohrid_age_depth_url_text)\n",
        "ohrid_xrf_francke_url <- getURL(ohrid_XRF_data_francke_url_text)\n",
        "ohrid_sediment_data_francke_url <- getURL(ohrid_sediment_data_francke_url_text)\n",
        "\n",
        "# Load data\n",
        "ohrid_raw_geochem <- read.csv(text = ohrid_geochem_url)\n",
        "ohrid_raw_ms <- read.csv(text = ohrid_ms_url)\n",
        "ohrid_raw_xrf <- read.csv(text = ohrid_xrf_url)\n",
        "ohrid_raw_pollen <- read.csv(text = ohrid_pollen_url)\n",
        "ohrid_agedepth <- read.csv(text = ohrid_agedepth_url)\n",
        "ohrid_raw_xrf_francke <- read.csv(text = ohrid_xrf_francke_url)\n",
        "ohrid_raw_sediment_francke <- read.csv(text = ohrid_sediment_data_francke_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNx_2O30sQ7e"
      },
      "source": [
        "# Process the Ohrid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTju1NNzsTpI"
      },
      "outputs": [],
      "source": [
        "# Process the geochemical data\n",
        "for (proxyname in c(\"Qz\", \"TIC\", \"TOC\", \"TN\", \"TS\", \"O18\", \"C13\")) {\n",
        "  # Dynamically create the column name to extract\n",
        "  data <- na.omit(ohrid_raw_geochem[c(\"geochem_depth\", proxyname)])\n",
        "\n",
        "  # Dynamically assign the data to a new variable with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), data)\n",
        "}\n",
        "\n",
        "# Process the pollen data\n",
        "AP_data <- na.omit(ohrid_raw_pollen[c(\"pollen_depth\", \"AP\")])\n",
        "Quercus_data <- na.omit(ohrid_raw_pollen[c(\"pollen_depth\", \"Quercus\")])\n",
        "\n",
        "# Process the XRF data and divide them to 1000 as in Wagner et al. (2019)\n",
        "K_data <- ohrid_raw_xrf %>%\n",
        "  select(xrf_depth, K) %>%\n",
        "  na.omit() %>%\n",
        "  mutate(K = K / 1000)\n",
        "Ca_data <- ohrid_raw_xrf %>%\n",
        "  select(xrf_depth, Ca) %>%\n",
        "  na.omit() %>%\n",
        "  mutate(Ca = Ca / 1000)\n",
        "\n",
        "# Process the magnetic susceptibility data\n",
        "MS_data <- na.omit(ohrid_raw_ms[c(\"MS_depth\", \"MS\")])\n",
        "\n",
        "# Process the sediment (Francke) data\n",
        "SR_data <- na.omit(ohrid_raw_sediment_francke[c(\"sediment_depth\", \"SR\")])\n",
        "Clay_data <- na.omit(ohrid_raw_sediment_francke[c(\"sediment_depth\", \"Clay\")])\n",
        "bSiO2_data <- na.omit(ohrid_raw_sediment_francke[c(\"sediment_depth\", \"bSiO2\")])\n",
        "\n",
        "# Process the XRF (Francke) data and divide Fe to 1000 as in Wagner et al. (2019)\n",
        "Fe_data <- ohrid_raw_xrf_francke %>%\n",
        "  select(xrf_francke_depth, Fe) %>%\n",
        "  na.omit() %>%\n",
        "  mutate(Fe = Fe / 1000)\n",
        "Zr_data <- na.omit(ohrid_raw_xrf_francke[c(\"xrf_francke_depth\", \"Zr\")])\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the t-distribution critical values for 6 df, see Christen and Perez 2010 abstract\n",
        "t_84 <- qt(0.84, df = 6)  # 1-sigma quantile (84%)\n",
        "t_975 <- qt(0.975, df = 6)  # 2-sigma quantile (97.5%)\n",
        "\n",
        "# Scaling factor\n",
        "scaling_factor <- t_84 / t_975\n",
        "\n",
        "options(warn=-1)\n",
        "\n",
        "# Loop over each covariate for geochem for interpolation of ages\n",
        "for (proxyname in c(\"Qz\", \"TIC\", \"TOC\", \"TN\", \"TS\", \"O18\", \"C13\")) {\n",
        "\n",
        "  # Retrieve the data for the current proxy\n",
        "  proxy_data <- get(paste0(proxyname, \"_data\"))\n",
        "\n",
        "  # Apply the interpolation and calculations\n",
        "  proxy_data <- proxy_data %>%\n",
        "    mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = geochem_depth, rule = 2)$y,\n",
        "           max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = geochem_depth, rule = 2)$y,\n",
        "           median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = geochem_depth, rule = 2)$y,\n",
        "           agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = geochem_depth, rule = 2)$y,\n",
        "           uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "           measurement_uncertainty = 0.01 * get(proxyname)\n",
        "    )\n",
        "\n",
        "  # Assign the updated data back to the environment with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), proxy_data)\n",
        "}\n",
        "\n",
        "# Loop over each covariate for pollen for interpolation of ages\n",
        "for (proxyname in c(\"AP\", \"Quercus\")) {\n",
        "\n",
        "  # Retrieve the data for the current proxy\n",
        "  proxy_data <- get(paste0(proxyname, \"_data\"))\n",
        "\n",
        "  # Apply the interpolation and calculations\n",
        "  proxy_data <- proxy_data %>%\n",
        "    mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = pollen_depth, rule = 2)$y,\n",
        "           max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = pollen_depth, rule = 2)$y,\n",
        "           median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = pollen_depth, rule = 2)$y,\n",
        "           agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = pollen_depth, rule = 2)$y,\n",
        "           uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "           measurement_uncertainty = 0.01 * get(proxyname)\n",
        "    )\n",
        "\n",
        "  # Assign the updated data back to the environment with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), proxy_data)\n",
        "}\n",
        "\n",
        "# Loop over each covariate for xrf  for interpolation of ages\n",
        "for (proxyname in c(\"Ca\", \"K\")) {\n",
        "\n",
        "  # Retrieve the data for the current proxy\n",
        "  proxy_data <- get(paste0(proxyname, \"_data\"))\n",
        "\n",
        "  # Apply the interpolation and calculations\n",
        "  proxy_data <- proxy_data %>%\n",
        "    mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = xrf_depth, rule = 2)$y,\n",
        "           max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = xrf_depth, rule = 2)$y,\n",
        "           median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = xrf_depth, rule = 2)$y,\n",
        "           agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = xrf_depth, rule = 2)$y,\n",
        "           uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "           measurement_uncertainty = 0.01 * get(proxyname)\n",
        "    )\n",
        "\n",
        "  # Assign the updated data back to the environment with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), proxy_data)\n",
        "}\n",
        "\n",
        "# Interpolate values for MS data depths\n",
        "MS_data <- MS_data %>%\n",
        "  mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = MS_depth, rule = 2)$y,\n",
        "         max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = MS_depth, rule = 2)$y,\n",
        "         median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = MS_depth, rule = 2)$y,\n",
        "         agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = MS_depth, rule = 2)$y,\n",
        "         uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "         measurement_uncertainty = 0.01 * MS_data$MS\n",
        "  )\n",
        "\n",
        "# Loop over each covariate for sediment  for interpolation of ages\n",
        "for (proxyname in c(\"Clay\", \"bSiO2\")) { #\"SR\",\n",
        "\n",
        "  # Retrieve the data for the current proxy\n",
        "  proxy_data <- get(paste0(proxyname, \"_data\"))\n",
        "\n",
        "  # Apply the interpolation and calculations\n",
        "  proxy_data <- proxy_data %>%\n",
        "    mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = sediment_depth, rule = 2)$y,\n",
        "           max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = sediment_depth, rule = 2)$y,\n",
        "           median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = sediment_depth, rule = 2)$y,\n",
        "           agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = sediment_depth, rule = 2)$y,\n",
        "           uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "           measurement_uncertainty = 0.01 * get(proxyname)\n",
        "    )\n",
        "\n",
        "  # Assign the updated data back to the environment with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), proxy_data)\n",
        "}\n",
        "\n",
        "# Loop over each covariate for XRF (francke)  for interpolation of ages\n",
        "for (proxyname in c(\"Fe\", \"Zr\")) {\n",
        "\n",
        "  # Retrieve the data for the current proxy\n",
        "  proxy_data <- get(paste0(proxyname, \"_data\"))\n",
        "\n",
        "  # Apply the interpolation and calculations\n",
        "  proxy_data <- proxy_data %>%\n",
        "    mutate(min = approx(ohrid_agedepth$depth, ohrid_agedepth$min, xout = xrf_francke_depth, rule = 2)$y,\n",
        "           max = approx(ohrid_agedepth$depth, ohrid_agedepth$max, xout = xrf_francke_depth, rule = 2)$y,\n",
        "           median = approx(ohrid_agedepth$depth, ohrid_agedepth$median, xout = xrf_francke_depth, rule = 2)$y,\n",
        "           agekaBP = approx(ohrid_agedepth$depth, ohrid_agedepth$wmean, xout = xrf_francke_depth, rule = 2)$y,\n",
        "           uncertainty_1sigma = (max - min) / 2 * scaling_factor,\n",
        "           measurement_uncertainty = 0.01 * get(proxyname)\n",
        "    )\n",
        "\n",
        "  # Assign the updated data back to the environment with the name \"<proxyname>_data\"\n",
        "  assign(paste0(proxyname, \"_data\"), proxy_data)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNu4vwpKUOaE"
      },
      "source": [
        "# Listing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp_-XSx3UMB1"
      },
      "outputs": [],
      "source": [
        "# Filter the data for a specific time range\n",
        "timescale = timescale\n",
        "time_range <- time_range\n",
        "kyrs_to_forecast <- kyrs_to_forecast\n",
        "resolution <- resolution # 0.5\n",
        "data_to_forecast <- data_to_forecast #\"O18\"\n",
        "# Specify the time points where you want to interpolate\n",
        "# Adjust the time sequences based on the timescale\n",
        "if (timescale == \"forwards\") {\n",
        "  new_time <- seq(time_range[1], time_range[2], by = -1 * resolution)\n",
        "  new_time_shrt <- seq(time_range[1], time_range[2] + kyrs_to_forecast, by = -1 * resolution)\n",
        "} else {\n",
        "  new_time <- seq(time_range[1], time_range[2], by = resolution)\n",
        "  new_time_shrt <- seq(time_range[1], time_range[2] - kyrs_to_forecast, by = resolution)\n",
        "}\n",
        "\n",
        "# List of datasets\n",
        "datasets <- lapply(covariatenames, function(name) get(paste0(name, \"_data\")))\n",
        "\n",
        "\n",
        "# Corresponding variable names\n",
        "var_names <- covariatenames\n",
        "\n",
        "# Corresponding proxy values and IDs\n",
        "proxy_values <- var_names\n",
        "proxy_ids <- 1:length(var_names)\n",
        "\n",
        "# Create cropped datasets with dynamic names\n",
        "if (timescale == \"forwards\") {\n",
        "  for (i in seq_along(datasets)) {\n",
        "    data <- datasets[[i]]\n",
        "    var_name <- var_names[i]\n",
        "    cropped_data <- data[data$agekaBP < time_range[1] & data$agekaBP > time_range[2], ]\n",
        "    dynamic_name <- paste0(var_name, \"_cropped\")\n",
        "    assign(dynamic_name, cropped_data)\n",
        "  }\n",
        "} else {\n",
        "  for (i in seq_along(datasets)) {\n",
        "    data <- datasets[[i]]\n",
        "    var_name <- var_names[i]\n",
        "    cropped_data <- data[data$agekaBP < time_range[2] & data$agekaBP > time_range[1], ]\n",
        "    dynamic_name <- paste0(var_name, \"_cropped\")\n",
        "    assign(dynamic_name, cropped_data)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Function to compute the centered log-ratio (CLR) transformation\n",
        "clr_transform <- function(data_matrix, pseudocount = 1e-10) {\n",
        "  # Ensure the input is a matrix\n",
        "  if (!is.matrix(data_matrix)) {\n",
        "    stop(\"Input must be a matrix.\")\n",
        "  }\n",
        "\n",
        "  # Replace zeros with the pseudocount\n",
        "  data_matrix[data_matrix == 0] <- pseudocount\n",
        "\n",
        "  # Compute the geometric mean for each row\n",
        "  geometric_mean <- apply(data_matrix, 1, function(row) exp(mean(log(row))))\n",
        "\n",
        "  # Perform CLR transformation: subtract log of the geometric mean from log of each element\n",
        "  clr_matrix <- log(data_matrix) - log(geometric_mean)\n",
        "\n",
        "  # Return the CLR-transformed matrix\n",
        "  return(clr_matrix)\n",
        "}\n",
        "\n",
        "# Keep published data\n",
        "Ca_cropped$Ca_published <- Ca_cropped$Ca\n",
        "Fe_cropped$Fe_published <- Fe_cropped$Fe\n",
        "K_cropped$K_published <- K_cropped$K\n",
        "Zr_cropped$Zr_published <- Zr_cropped$Zr\n",
        "\n",
        "# Treat XRF data as compositional, and transform to clr\n",
        "XRF_cropped <- cbind(Ca_cropped$Ca_published, Fe_cropped$Fe_published, K_cropped$K_published, Zr_cropped$Zr_published)\n",
        "XRF_cropped_clr <- clr_transform(XRF_cropped)\n",
        "\n",
        "# Assign transformed data\n",
        "Ca_cropped$Ca <- XRF_cropped_clr[ ,1]\n",
        "Fe_cropped$Fe <- XRF_cropped_clr[ ,2]\n",
        "K_cropped$K <- XRF_cropped_clr[ ,3]\n",
        "Zr_cropped$Zr <- XRF_cropped_clr[ ,4]\n",
        "\n",
        "# Initialize empty vectors\n",
        "covariates_agekaBP <- c()\n",
        "covariates_age_uncertainty <- c()\n",
        "covariates_proxy_value <- c()\n",
        "covariates_proxy_uncertainty <- c()\n",
        "covariates_proxy_id <- c()\n",
        "covariates_time_idx <- c()\n",
        "\n",
        "# Loop through each cropped dataset and extract the necessary values\n",
        "\n",
        "if (timescale == \"forwards\") {\n",
        "  # Sort new_time in increasing order\n",
        "  new_time_sorted <- sort(new_time)\n",
        "\n",
        "  for (i in seq_along(var_names)) {\n",
        "    var_name <- var_names[i]\n",
        "    proxy_value <- proxy_values[i]\n",
        "    proxy_id <- proxy_ids[i]\n",
        "\n",
        "    dynamic_name <- paste0(var_name, \"_cropped\")\n",
        "    if (exists(dynamic_name)) {\n",
        "      cropped_data <- get(dynamic_name)\n",
        "\n",
        "      # Append data for each variable\n",
        "      covariates_agekaBP <- c(covariates_agekaBP, cropped_data$agekaBP)\n",
        "      covariates_age_uncertainty <- c(covariates_age_uncertainty, cropped_data$uncertainty_1sigma)\n",
        "      covariates_proxy_value <- c(covariates_proxy_value, cropped_data[[proxy_value]])\n",
        "      covariates_proxy_uncertainty <- c(covariates_proxy_uncertainty, cropped_data$measurement_uncertainty)\n",
        "      covariates_proxy_id <- c(covariates_proxy_id, rep(proxy_id, nrow(cropped_data)))\n",
        "\n",
        "      # Use findInterval with sorted new_time\n",
        "      time_idx <- findInterval(cropped_data$agekaBP, new_time_sorted)\n",
        "\n",
        "      # Reverse the indices for \"forwards\" case\n",
        "      reversed_time_idx <- length(new_time_sorted) - time_idx + 1\n",
        "\n",
        "      # Append the reversed indices\n",
        "      covariates_time_idx <- c(covariates_time_idx, reversed_time_idx)\n",
        "    }\n",
        "  }\n",
        "} else {\n",
        "  # For backwards case, no sorting or reversing needed\n",
        "  for (i in seq_along(var_names)) {\n",
        "    var_name <- var_names[i]\n",
        "    proxy_value <- proxy_values[i]\n",
        "    proxy_id <- proxy_ids[i]\n",
        "\n",
        "    dynamic_name <- paste0(var_name, \"_cropped\")\n",
        "    if (exists(dynamic_name)) {\n",
        "      cropped_data <- get(dynamic_name)\n",
        "\n",
        "      # Append data for each variable\n",
        "      covariates_agekaBP <- c(covariates_agekaBP, cropped_data$agekaBP)\n",
        "      covariates_age_uncertainty <- c(covariates_age_uncertainty, cropped_data$uncertainty_1sigma)\n",
        "      covariates_proxy_value <- c(covariates_proxy_value, cropped_data[[proxy_value]])\n",
        "      covariates_proxy_uncertainty <- c(covariates_proxy_uncertainty, cropped_data$measurement_uncertainty)\n",
        "      covariates_proxy_id <- c(covariates_proxy_id, rep(proxy_id, nrow(cropped_data)))\n",
        "\n",
        "      # Find interval without reversing in the forwards case\n",
        "      covariates_time_idx <- c(covariates_time_idx, findInterval(cropped_data$agekaBP, new_time))\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Combine the data with new indices\n",
        "combined_data <- data.frame(\n",
        "  covariates_agekaBP = covariates_agekaBP,\n",
        "  covariates_age_uncertainty = covariates_age_uncertainty,\n",
        "  covariates_proxy_value = covariates_proxy_value,\n",
        "  covariates_proxy_uncertainty = covariates_proxy_uncertainty,\n",
        "  covariates_proxy_id = covariates_proxy_id,\n",
        "  covariates_time_idx = covariates_time_idx\n",
        "  )\n",
        "\n",
        "# Add the new column with corresponding covariate names\n",
        "combined_data$covariate_name <- covariatenames[combined_data$covariates_proxy_id]\n",
        "\n",
        "\n",
        "\n",
        "# Create cropped datasets with dynamic names\n",
        "# Define the variable dynamically\n",
        "data_variable <- get(paste0(data_to_forecast, \"_data\"))\n",
        "\n",
        "# Create cropped datasets with dynamic names based on timescale and data_to_forecast\n",
        "if (timescale == \"forwards\") {\n",
        "  dependent_cropped <- data_variable[data_variable$agekaBP < (time_range[1]) & data_variable$agekaBP > time_range[2] + kyrs_to_forecast, ]\n",
        "} else {\n",
        "  dependent_cropped <- data_variable[data_variable$agekaBP < (time_range[2] - kyrs_to_forecast) & data_variable$agekaBP > time_range[1], ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWnnLJr0Qi6Q"
      },
      "source": [
        "# Plot raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf1mhCzI73Uz"
      },
      "outputs": [],
      "source": [
        "# Plotting the raw data\n",
        "###########################################\n",
        "# Prepare data\n",
        "if (timescale == \"forwards\") {\n",
        "  dependent_toplot <- data_variable[data_variable$agekaBP < time_range[1] & data_variable$agekaBP > time_range[2], ]\n",
        "} else {\n",
        "  dependent_toplot <- data_variable[data_variable$agekaBP < time_range[2] & data_variable$agekaBP > time_range[1], ]\n",
        "}\n",
        "\n",
        "# List of cropped dataframes and their corresponding columns\n",
        "cropped_data_list <- lapply(covariatenames, function(name) get(paste0(name, \"_cropped\")))\n",
        "\n",
        "# Corresponding variable names\n",
        "var_names <- covariatenames\n",
        "\n",
        "# Create combined dataframe using a loop\n",
        "combined_plot_data <- do.call(rbind, lapply(seq_along(cropped_data_list), function(i) {\n",
        "  data.frame(agekaBP = cropped_data_list[[i]]$agekaBP,\n",
        "             value = cropped_data_list[[i]][[var_names[i]]],\n",
        "             variable = var_names[i])\n",
        "}))\n",
        "\n",
        "# Add the dependent variable\n",
        "combined_plot_data <- rbind(\n",
        "  combined_plot_data,\n",
        "  data.frame(agekaBP = dependent_toplot$agekaBP, value = dependent_toplot[[data_to_forecast]], variable = data_to_forecast)\n",
        ")\n",
        "\n",
        "# Set the order of the variable levels\n",
        "combined_plot_data$variable <- factor(combined_plot_data$variable, levels = c(var_names, data_to_forecast))\n",
        "\n",
        "# Add a column to conditionally color the O18 plot\n",
        "if (timescale == \"forwards\") {\n",
        "  combined_plot_data$color <- ifelse(combined_plot_data$variable == data_to_forecast & combined_plot_data$agekaBP < (time_range[2] + kyrs_to_forecast), \"red\", \"black\")\n",
        "} else {\n",
        "  combined_plot_data$color <- ifelse(combined_plot_data$variable == data_to_forecast & combined_plot_data$agekaBP > (time_range[2] - kyrs_to_forecast), \"red\", \"black\")\n",
        "}\n",
        "\n",
        "# Separate the dependent data for custom styling\n",
        "dependent_data <- combined_plot_data[combined_plot_data$variable == data_to_forecast & combined_plot_data$color == \"red\", ]\n",
        "\n",
        "# Plotting data\n",
        "if (timescale == \"forwards\") {\n",
        "  # Plot with facet_wrap and custom color\n",
        "  plotraw <- ggplot() +\n",
        "    # Lines for all data excluding the red-colored dependent data\n",
        "    geom_line(data = combined_plot_data[!(combined_plot_data$variable == data_to_forecast & combined_plot_data$color == \"red\"), ],\n",
        "              aes(x = agekaBP, y = value, color = color)) +\n",
        "    # Points for the red-colored dependent data\n",
        "    geom_point(data = dependent_data, aes(x = agekaBP, y = value, color = color), size =0.1) +\n",
        "    # Add a vertical line\n",
        "    geom_vline(xintercept = (time_range[2] + kyrs_to_forecast), linetype = \"dashed\", color = \"red\") +\n",
        "    # Facet wrap\n",
        "    facet_wrap(~ variable, scales = \"free_y\", ncol = 2) +\n",
        "    scale_y_continuous(n.breaks = 3)+\n",
        "    scale_color_identity() +\n",
        "    labs(x = \"Age (ka BP)\", y = \"Value\") +\n",
        "    theme_bw()#+\n",
        "    #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "} else {\n",
        "  # Plot with facet_wrap and custom color\n",
        "  plotraw <- ggplot() +\n",
        "    # Lines for all data excluding the red-colored dependent data\n",
        "    geom_line(data = combined_plot_data[!(combined_plot_data$variable == data_to_forecast & combined_plot_data$color == \"red\"), ],\n",
        "              aes(x = agekaBP, y = value, color = color)) +\n",
        "    # Points for the red-colored dependent data\n",
        "    geom_point(data = dependent_data, aes(x = agekaBP, y = value, color = color), size =0.1) +\n",
        "    # Add a vertical line\n",
        "    geom_vline(xintercept = (time_range[2] - kyrs_to_forecast), linetype = \"dashed\", color = \"red\") +\n",
        "    # Facet wrap\n",
        "    facet_wrap(~ variable, scales = \"free_y\", ncol = 2) +\n",
        "    scale_y_continuous(n.breaks = 3)+\n",
        "    scale_color_identity() +\n",
        "    labs(x = \"Age (ka BP)\", y = \"Value\") +\n",
        "    theme_bw()#+\n",
        "    #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "}\n",
        "\n",
        "# Display the plot\n",
        "print(plotraw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vpa2Km1uq87"
      },
      "source": [
        "# Prepare the data for Jags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVXJKpucutwC"
      },
      "outputs": [],
      "source": [
        "# Calculate means and standard deviations\n",
        "mean_y <- tapply(combined_data$covariates_proxy_value, combined_data$covariates_proxy_id, mean)\n",
        "sd_y <- tapply(combined_data$covariates_proxy_value, combined_data$covariates_proxy_id, sd)\n",
        "\n",
        "# Standardize y\n",
        "y_std <- numeric(length(combined_data$covariates_proxy_value))\n",
        "for (i in 1:length(combined_data$covariates_proxy_value)) {\n",
        "  y_std[i] <- (combined_data$covariates_proxy_value[i] - mean_y[covariates_proxy_id[i]]) / sd_y[covariates_proxy_id[i]]\n",
        "}\n",
        "\n",
        "# Precompute norm_prob for each covariate based on time_idx and age_error_sd\n",
        "int_range <- 3\n",
        "N_obs <- nrow(combined_data)\n",
        "N <- length(new_time)\n",
        "n_proxies <- length(unique(combined_data$covariates_proxy_id))\n",
        "\n",
        "# Initialize the matrix with zeros\n",
        "norm_prob_covariate <- matrix(0, nrow = N_obs, ncol = N)\n",
        "\n",
        "# Loop over each observation to calculate and normalize probabilities within int_range\n",
        "# if (timescale == \"backwards\") {\n",
        "for (i in 1:N_obs) {\n",
        "  # Define the subsetting range for each observation\n",
        "  start_idx <- max(1, combined_data$covariates_time_idx[i] - int_range)\n",
        "  end_idx <- min(N, combined_data$covariates_time_idx[i] + int_range)\n",
        "\n",
        "  # Calculate probabilities within the subsetting range\n",
        "  prob_slice <- dnorm(start_idx:end_idx, mean = combined_data$covariates_time_idx[i],\n",
        "                      sd = combined_data$covariates_age_uncertainty[i])\n",
        "\n",
        "  # Normalize the calculated probabilities\n",
        "  prob_slice <- prob_slice / sum(prob_slice)\n",
        "\n",
        "  # Assign normalized probabilities back to the sparse matrix within range\n",
        "  norm_prob_covariate[i, start_idx:end_idx] <- prob_slice\n",
        "}\n",
        "\n",
        "\n",
        "# Define JAGS data for the covariates\n",
        "jags_data_covariates <- list(\n",
        "  int_range = 3,  # Pass int_range from R\n",
        "  y_std = y_std,\n",
        "  # y = combined_data$covariates_proxy_value,\n",
        "  proxy_id = combined_data$covariates_proxy_id,\n",
        "  time_idx = combined_data$covariates_time_idx,\n",
        "  n_proxies = length(unique(combined_data$covariates_proxy_id)),\n",
        "  N = length(new_time),\n",
        "  N_obs = nrow(combined_data),\n",
        "  age_error_sd = combined_data$covariates_age_uncertainty,\n",
        "  proxy_error_sd = combined_data$covariates_proxy_uncertainty,\n",
        "  mean_y = mean_y,\n",
        "  age_ka_BP = combined_data$covariates_agekaBP,\n",
        "  sd_y = sd_y,\n",
        "  norm_prob_covariate = norm_prob_covariate\n",
        ")\n",
        "\n",
        "# Calculate means and standard deviations for each covariate\n",
        "###############################\n",
        "# List of proxy names\n",
        "covariatenames <- var_names\n",
        "\n",
        "# Initialize lists to store means and standard deviations\n",
        "mean_list <- list()\n",
        "sd_list <- list()\n",
        "\n",
        "# Loop over each proxy\n",
        "for (proxyname in covariatenames) {\n",
        "\n",
        "  # Get the cropped data dynamically\n",
        "  proxy_data <- get(paste0(proxyname, \"_cropped\"))\n",
        "\n",
        "  # Calculate mean and standard deviation\n",
        "  mean_value <- mean(proxy_data[[proxyname]], na.rm = TRUE)\n",
        "  sd_value <- sd(proxy_data[[proxyname]], na.rm = TRUE)\n",
        "\n",
        "  # Store the results in the lists\n",
        "  mean_list[[proxyname]] <- mean_value\n",
        "  sd_list[[proxyname]] <- sd_value\n",
        "}\n",
        "\n",
        "\n",
        "if (timescale == \"forwards\") {\n",
        "  new_time_shrt_sorted <- sort(new_time_shrt)\n",
        "  time_idx_shrt = findInterval(dependent_cropped$agekaBP, new_time_shrt_sorted)\n",
        "  reversed_time_idx_shrt <- length(new_time_shrt_sorted) - time_idx_shrt + 1\n",
        "  jags_data_dependent <- list(\n",
        "    int_range = 3,  # Pass int_range from R\n",
        "    y_shrt = dependent_cropped[[data_to_forecast]],\n",
        "    N_obs_shrt = nrow(dependent_cropped),\n",
        "    N_shrt = length(new_time_shrt),\n",
        "    time_idx_shrt = reversed_time_idx_shrt,\n",
        "    age_error_sd = dependent_cropped$uncertainty_1sigma,\n",
        "    proxy_error_sd = dependent_cropped$measurement_uncertainty,\n",
        "    age_ka_BP = dependent_cropped$median\n",
        "  )\n",
        "} else {\n",
        "  jags_data_dependent <- list(\n",
        "    int_range = 3,  # Pass int_range from R\n",
        "    y_shrt = dependent_cropped[[data_to_forecast]],\n",
        "    N_obs_shrt = nrow(dependent_cropped),\n",
        "    N_shrt = length(new_time_shrt),\n",
        "    time_idx_shrt = findInterval(dependent_cropped$agekaBP, new_time_shrt),\n",
        "    age_error_sd = dependent_cropped$uncertainty_1sigma,\n",
        "    proxy_error_sd = dependent_cropped$measurement_uncertainty,\n",
        "    age_ka_BP = dependent_cropped$median\n",
        "  )\n",
        "}\n",
        "\n",
        "# Initialize sparse matrix with zeros\n",
        "norm_prob_dependent <- matrix(0, nrow = jags_data_dependent$N_obs_shrt, ncol = jags_data_dependent$N_shrt)\n",
        "\n",
        "# Loop over each observation to calculate and normalize probabilities within int_range\n",
        "for (i in 1:jags_data_dependent$N_obs_shrt) {\n",
        "  # Define valid index range\n",
        "  start_idx <- max(1, jags_data_dependent$time_idx_shrt[i] - int_range)\n",
        "  end_idx <- min(jags_data_dependent$N_shrt, jags_data_dependent$time_idx_shrt[i] + int_range)\n",
        "\n",
        "  # Compute probability slice only for the relevant range\n",
        "  # time_range <- start_idx:end_idx\n",
        "  prob_dependent <- dnorm(start_idx:end_idx, mean = jags_data_dependent$time_idx_shrt[i], sd = jags_data_dependent$age_error_sd[i])\n",
        "\n",
        "  # Normalize and assign only to the sparse subset\n",
        "  norm_prob_dependent[i, start_idx:end_idx] <- prob_dependent / sum(prob_dependent)\n",
        "}\n",
        "\n",
        "\n",
        "jags_data_dependent$norm_prob_dependent <- norm_prob_dependent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi5jTmI-uxri"
      },
      "source": [
        "# Define the Jags function for KF of covarietes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpemlFtLu2g3"
      },
      "outputs": [],
      "source": [
        "kf_covariates_jags <- function(jags_data,\n",
        "                               #new_time,\n",
        "                               #new_time_shrt,\n",
        "                               n.chains = 3,\n",
        "                               burnin = 1000,\n",
        "                               adapt = 2000,\n",
        "                               sample = 3000,\n",
        "                               thin = 2,\n",
        "                               initlist = NA,\n",
        "                               model = \"noerror\" # \"noerror\" \"eiv\" \"onlyageerror\"\n",
        "                               ) {\n",
        "\n",
        "  kf_covariates_model <- \"\n",
        "    model {\n",
        "  # Process noise and observation noise\n",
        "  sigma_proc ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "  sigma_obs ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "\n",
        "        # Initial state\n",
        "        x_std[1] ~ dnorm(0, 4^-2)\n",
        "\n",
        "        for (t in 2:N) {\n",
        "          x_std[t] ~ dnorm(x_std[t-1], 1 / sigma_proc^2)\n",
        "        }\n",
        "\n",
        "      for (i in 1:N_obs) {\n",
        "        y_std[i] ~ dnorm(x_std[time_idx[i]], 1 / sigma_obs^2)\n",
        "      }\n",
        "      # Back transform\n",
        "        for (t in 1:N) {\n",
        "          x[t] <- x_std[t] * sd_y + mean_y\n",
        "        }\n",
        "    }\n",
        "    \"\n",
        "\n",
        "\n",
        "kf_covariates_model_ageerror <- \"\n",
        "model {\n",
        "\n",
        "  # Process noise and observation noise\n",
        "  sigma_proc ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "  sigma_obs ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "\n",
        "  # Initial state\n",
        "  x_std[1] ~ dnorm(0, 4^-2)\n",
        "\n",
        "  for (t in 2:N) {\n",
        "    x_std[t] ~ dnorm(x_std[t-1], 1 / sigma_proc^2)\n",
        "  }\n",
        "\n",
        "   for (i in 1:N_obs) {\n",
        "\n",
        "    # Latent time index as a categorical variable using precomputed norm_prob\n",
        "    true_time_idx[i] ~ dcat(norm_prob_covariate[i, 1:N])\n",
        "\n",
        "    # Observation model with the latent time index\n",
        "    y_std[i] ~ dnorm(x_std[true_time_idx[i]], 1 / (sigma_obs^2))\n",
        "  }\n",
        "\n",
        "  # Back transform\n",
        "  for (t in 1:N) {\n",
        "    x[t] <- x_std[t] * sd_y + mean_y\n",
        "  }\n",
        "}\n",
        "\"\n",
        "\n",
        "\n",
        "  if (model == \"noerror\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"kalman_model.jags\"\n",
        "    writeLines(kf_covariates_model, con = model)\n",
        "    parameters <- c(\"x\", \"sigma_proc\", \"sigma_obs\")\n",
        "  } else if (model == \"onlyageerror\"){\n",
        "    # Write the model to a file\n",
        "    model <- \"kalman_model.jags\"\n",
        "    writeLines(kf_covariates_model_ageerror, con = model)\n",
        "    parameters <- c(\"x\", \"sigma_proc\", \"sigma_obs\")\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  # Run the JAGS model\n",
        "  jags_covariates_kf_model <- run.jags(\n",
        "    model = model,\n",
        "    data = jags_data,\n",
        "    monitor = parameters,\n",
        "    n.chains = n.chains,\n",
        "    burnin = burnin,\n",
        "    sample = sample,\n",
        "    adapt = adapt,\n",
        "    thin = thin,\n",
        "    method=\"parallel\"\n",
        "  )\n",
        "\n",
        "  return(jags_covariates_kf_model)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKoNf1UWiFFS"
      },
      "source": [
        "# Run the KF for the covariates Jags model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb4CTGAgyMEA"
      },
      "outputs": [],
      "source": [
        "# To store results from each proxy\n",
        "jags_model_result_covariates_list <- list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCXCjjJxUVwT"
      },
      "outputs": [],
      "source": [
        "# Loop through each proxy\n",
        "for (i in 1:length(covariatenames)) {#jags_data_covariates$n_proxies) { 1:length(covariatenames)\n",
        "\n",
        "  # Filter data for the current proxy\n",
        "   # Filter data for the current proxy\n",
        "  jags_data_subset <- list(\n",
        "    y_std = jags_data_covariates$y_std[jags_data_covariates$proxy_id == i],\n",
        "    time_idx = jags_data_covariates$time_idx[jags_data_covariates$proxy_id == i],\n",
        "    N_obs = sum(jags_data_covariates$proxy_id == i),\n",
        "    N = jags_data_covariates$N,\n",
        "    # age_error_sd = jags_data_covariates$age_error_sd[jags_data_covariates$proxy_id == i],\n",
        "    # proxy_error_sd = jags_data_covariates$proxy_error_sd[jags_data_covariates$proxy_id == i],\n",
        "    mean_y = as.numeric(jags_data_covariates$mean_y[i]),\n",
        "    sd_y = as.numeric(jags_data_covariates$sd_y[i]),\n",
        "    # int_range = 3,\n",
        "    age_ka_BP = jags_data_covariates$age_ka_BP[jags_data_covariates$proxy_id == i],\n",
        "    norm_prob_covariate = jags_data_covariates$norm_prob_covariate[jags_data_covariates$proxy_id == i,]\n",
        "    # n_proxies = 1  # Only one proxy in the subset\n",
        "  )\n",
        "\n",
        "  # Compute the differences between consecutive ages\n",
        "  age_spacings <- diff(sort(jags_data_covariates$age_ka_BP[jags_data_covariates$proxy_id == i]))\n",
        "  # Select a quantile threshold (e.g., 25th percentile)\n",
        "  criterion <- quantile(age_spacings, 0.5)\n",
        "\n",
        "\n",
        "  # assign the model type according to the observation points of each proxy\n",
        "  if (criterion > (0.5)) {\n",
        "    kf_model <- \"onlyageerror\"\n",
        "  } else {\n",
        "    kf_model <- \"noerror\"\n",
        "  }\n",
        "\n",
        "  inits <- list(\n",
        "  list(\n",
        "    sigma_proc = 0.05,\n",
        "    sigma_obs = 0.1,\n",
        "    true_time = jags_data_subset$age_ka_BP\n",
        "  ),\n",
        "  list(\n",
        "    sigma_proc = 0.2,\n",
        "    sigma_obs = 0.05,\n",
        "    true_time = jags_data_subset$age_ka_BP\n",
        "  ),\n",
        "  list(\n",
        "    sigma_proc = 0.1,\n",
        "    sigma_obs = 0.2,\n",
        "    true_time = jags_data_subset$age_ka_BP\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "  # Run the covariates model for this proxy\n",
        "  jags_model_result_covariates <- kf_covariates_jags(\n",
        "    jags_data = jags_data_subset,\n",
        "    n.chains = 3,\n",
        "    burnin = 1000,\n",
        "    adapt = 500,\n",
        "    sample = 2000,\n",
        "    thin = 10,\n",
        "    initlist = NA, #inits,  # Assuming you have the inits defined\n",
        "    model = kf_model #\"noerror\"  # Modify as needed for different models: \"noerror\", \"eiv\" \"fullstochastic\" \"onlyageerror\"\n",
        "  )\n",
        "\n",
        "  # Store the results\n",
        "  jags_model_result_covariates_list[[i]] <- jags_model_result_covariates\n",
        "\n",
        "  # Optionally print progress\n",
        "  print(paste(\"Completed proxy:\", i))\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqvlV8Mv6pJX"
      },
      "source": [
        "# Extend results if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y63lXzmg53da"
      },
      "outputs": [],
      "source": [
        "# ---------- CHECK CONVERGENCE AND EXTEND IF NEEDED ----------\n",
        "for (i in 1:length(covariatenames)) {\n",
        "  model_result <- jags_model_result_covariates_list[[i]]\n",
        "\n",
        "  # Convert to coda object for diagnostics\n",
        "  coda_samples <- as.mcmc.list(model_result)\n",
        "\n",
        "  # Compute Gelman-Rubin statistic\n",
        "  gelman_result <- tryCatch(gelman.diag(coda_samples), error = function(e) NULL)\n",
        "\n",
        "  if (!is.null(gelman_result)) {\n",
        "    # Extract max potential scale reduction factor (PSRF)\n",
        "    max_psrf <- max(gelman_result$psrf[, 1], na.rm = TRUE)\n",
        "\n",
        "    if (max_psrf > 1.1) {  # Common threshold for non-convergence\n",
        "      print(paste(\"Extending run for proxy\", i, \"due to poor convergence (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "\n",
        "      # Extend the MCMC run\n",
        "      extended_results <- extend.JAGS(model_result,\n",
        "                                      burnin = 0,\n",
        "                                      sample = 20)\n",
        "\n",
        "      # Update stored results\n",
        "      jags_model_result_covariates_list[[i]] <- extended_results\n",
        "\n",
        "      print(paste(\"Extended run for proxy:\", i))\n",
        "    } else {\n",
        "      print(paste(\"Proxy\", i, \"has converged (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "    }\n",
        "  } else {\n",
        "    print(paste(\"Gelman diagnostic failed for proxy:\", i))\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AelrZXfgUHTb"
      },
      "source": [
        "# Save image up to here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EZUhuewUBhK"
      },
      "outputs": [],
      "source": [
        "nameworkspace <- paste(\"workspace_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".Rdata\", sep = \"\")\n",
        "save.image(file=paste(\"workspace_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".Rdata\", sep = \"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scEV-th9voK4"
      },
      "source": [
        "# Define the Jags function for KF of the dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Ps5FBbvp-e"
      },
      "outputs": [],
      "source": [
        "kf_dependent_jags <- function(jags_data,\n",
        "                              n.chains = 3,\n",
        "                              burnin = 1000,\n",
        "                              adapt = 2000,\n",
        "                              sample = 3000,\n",
        "                              thin = 2,\n",
        "                              initlist = NA,\n",
        "                              model = \"noerror\" # \"noerror\" \"eiv\" \"onlyageerror\"\n",
        "                              ) {\n",
        "\n",
        "  kf_dependent_model <- \"\n",
        "    data {\n",
        "      ym <- mean(y_shrt)\n",
        "      ysd <- sd(y_shrt)\n",
        "      for ( i in 1:N_obs_shrt ) {\n",
        "        y_shrt_std[i] <- (y_shrt[i] - ym) / ysd\n",
        "      }\n",
        "    }\n",
        "    model {\n",
        "    # Process noise and observation noise\n",
        "    sigma_proc_shrt ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "    sigma_obs_shrt ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "\n",
        "      # Initial state\n",
        "      x_shrt_std[1] ~ dnorm(0, 4^-2)\n",
        "\n",
        "      for (t in 2:N_shrt) {\n",
        "        x_shrt_std[t] ~ dnorm(x_shrt_std[t-1], 1 / sigma_proc_shrt^2)\n",
        "      }\n",
        "\n",
        "      for (md in 1:N_obs_shrt){\n",
        "        y_shrt_std[md] ~ dnorm(x_shrt_std[time_idx_shrt[md]], 1 / sigma_obs_shrt^2)\n",
        "      }\n",
        "      # Back transform\n",
        "      for (t in 1:N_shrt) {\n",
        "      x_shrt[t] <- x_shrt_std[t] * ysd + ym\n",
        "  }\n",
        "    }\n",
        "  \"\n",
        "\n",
        "\n",
        "kf_dependent_model_ageerror <- \"\n",
        "data {\n",
        "  ym <- mean(y_shrt)\n",
        "  ysd <- sd(y_shrt)\n",
        "  for (i in 1:N_obs_shrt) {\n",
        "    y_shrt_std[i] <- (y_shrt[i] - ym) / ysd\n",
        "  }\n",
        "}\n",
        "\n",
        "model {\n",
        "\n",
        "  # Process noise and observation noise\n",
        "  sigma_proc_shrt ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "  sigma_obs_shrt ~ dt(0, 1 / (1^2), 1) T(0, )\n",
        "\n",
        "\n",
        "  # Initial state\n",
        "  x_shrt_std[1] ~ dnorm(0, 4^-2)  # Prior for initial state\n",
        "\n",
        "  # State process with Gaussian random walk\n",
        "  for (t in 2:N_shrt) {\n",
        "    x_shrt_std[t] ~ dnorm(x_shrt_std[t-1], 1 / sigma_proc_shrt^2)\n",
        "  }\n",
        "\n",
        "  for (i in 1:N_obs_shrt) {\n",
        "    # Latent time index as a categorical variable using precomputed norm_prob_dependent\n",
        "    true_time_idx_shrt[i] ~ dcat(norm_prob_dependent[i, 1:N_shrt])\n",
        "\n",
        "    # Observation model with the latent time index\n",
        "    y_shrt_std[i] ~ dnorm(x_shrt_std[true_time_idx_shrt[i]], 1 / sigma_obs_shrt^2)\n",
        "  }\n",
        "\n",
        "\n",
        "  # Back-transform for output\n",
        "  for (t in 1:N_shrt) {\n",
        "    x_shrt[t] <- x_shrt_std[t] * ysd + ym\n",
        "  }\n",
        "}\n",
        "\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  if (model == \"noerror\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"kalman_model_dependent.jags\"\n",
        "    writeLines(kf_dependent_model, con = model)\n",
        "    parameters <- c(\"x_shrt\", \"sigma_proc_shrt\", \"sigma_obs_shrt\")\n",
        "  } else if (model == \"onlyageerror\"){\n",
        "    # Write the model to a file\n",
        "    model <- \"kalman_model.jags\"\n",
        "    writeLines(kf_dependent_model_ageerror, con = model)\n",
        "    parameters <- c(\"x_shrt\", \"sigma_proc_shrt\", \"sigma_obs_shrt\", \"sigma_age_shrt\")\n",
        "  }\n",
        "\n",
        "\n",
        "  # Run the JAGS model\n",
        "  jags_dependent_kf_model <- run.jags(\n",
        "    model = model,\n",
        "    data = jags_data,\n",
        "    monitor = parameters,\n",
        "    n.chains = n.chains,\n",
        "    burnin = burnin,\n",
        "    sample = sample,\n",
        "    adapt = adapt,\n",
        "    thin = thin,\n",
        "    method = \"parallel\"\n",
        "  )\n",
        "\n",
        "  return(jags_dependent_kf_model)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcjnUZOmvXJh"
      },
      "source": [
        "# Run the KF for dependent Jags model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9cx_6SK6vWVK"
      },
      "outputs": [],
      "source": [
        "# Run the dependent model\n",
        "jags_model_result_dependent <- kf_dependent_jags(\n",
        "  jags_data = jags_data_dependent,\n",
        "  n.chains = 3,\n",
        "  burnin = 2000,\n",
        "  adapt = 1000,\n",
        "  sample = 4000,\n",
        "  thin = 2,\n",
        "  #initlist = inits_dependent,\n",
        "  model = \"onlyageerror\" # \"noerror\" \"eiv\" \"onlyageerror\" \"fullstochastic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVNbEeYAbotH",
        "outputId": "3cc1cb00-089c-472b-8d5d-c74480f83a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Gelman diagnostic failed for proxy: 13\"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "  # Convert to coda object for diagnostics\n",
        "  coda_samples_dependent <- as.mcmc.list(jags_model_result_dependent)\n",
        "\n",
        "  # Compute Gelman-Rubin statistic\n",
        "  gelman_result_dependent <- tryCatch(gelman.diag(coda_samples), error = function(e) NULL)\n",
        "\n",
        "  if (!is.null(gelman_result_dependent)) {\n",
        "    # Extract max potential scale reduction factor (PSRF)\n",
        "    max_psrf <- max(gelman_result_dependent$psrf[, 1], na.rm = TRUE)\n",
        "\n",
        "    if (max_psrf > 1.1) {  # Common threshold for non-convergence\n",
        "      print(paste(\"Extending run for proxy due to poor convergence (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "\n",
        "      # Extend the MCMC run\n",
        "      extended_results <- extend.JAGS(jags_model_result_dependent,\n",
        "                                      burnin = 0,\n",
        "                                      sample = 2000)\n",
        "\n",
        "      # Update stored results\n",
        "      jags_model_result_dependent <- extended_results\n",
        "\n",
        "      print(paste(\"Extended run for proxy\"))\n",
        "    } else {\n",
        "      print(paste(\"Proxy has converged (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "    }\n",
        "  } else {\n",
        "    print(paste(\"Gelman diagnostic failed for proxy:\", i))\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJilsOOwvbuQ"
      },
      "source": [
        "# Trace plots of KF runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg0UeVFNvbKH"
      },
      "outputs": [],
      "source": [
        "mcmc_trace_covariates_pars_kf <- c(\"sigma_proc\", \"sigma_obs\")\n",
        "\n",
        "mcmc_trace_dependent_pars_kf <- c(\"sigma_proc_shrt\", \"sigma_obs_shrt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FszfqkuGwr5a"
      },
      "outputs": [],
      "source": [
        "mcmc_trace_list <- lapply(1:length(jags_model_result_covariates_list), function(i) {\n",
        "  mcmc_trace(jags_model_result_covariates_list[[i]]$mcmc, pars = mcmc_trace_covariates_pars_kf) +\n",
        "    ggtitle(paste(\"KF trace plots - \", covariatenames[i])) +  # Use covariate names in the title\n",
        "    theme(plot.title = element_text(size = 10, hjust = .5)) +\n",
        "    theme(legend.position = \"none\",\n",
        "          axis.text = element_text(size = 10),\n",
        "          axis.title = element_text(size = 11)) +\n",
        "    theme(axis.title.x = element_blank(),\n",
        "          axis.text.x = element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.text.y= element_blank(),\n",
        "          strip.text = element_text(size = 5)\n",
        "          #, text=element_text(family=\"LM Sans 10\")\n",
        "          )\n",
        "})\n",
        "\n",
        "\n",
        "# Create a single plot by combining all plots in mcmc_trace_list using patchwork\n",
        "mcmc_trace_covariates_kf <- wrap_plots(mcmc_trace_list, ncol = 3) +  # Adjust ncol for desired layout\n",
        "  plot_annotation(title = paste(\"KF trace plots \", time_range[1],\"-\", time_range[2]),\n",
        "                  theme = theme(plot.title = element_text(size = 25, hjust = .5) #,family=\"LM Sans 10\")\n",
        "                  )\n",
        "\n",
        "# Display the combined plot\n",
        "# print(mcmc_trace_covariates_kf)\n",
        "\n",
        "\n",
        "mcmc_trace_dependent_kf <- mcmc_trace(jags_model_result_dependent$mcmc, pars = mcmc_trace_dependent_pars_kf) +\n",
        "  ggtitle(paste(\"KF trace plots - \", data_to_forecast)) +\n",
        "  #theme(text=element_text(family=\"LM Sans 10\")) +\n",
        "  theme(plot.title = element_text(size = 10, hjust = .5)) +\n",
        "    theme(legend.position = \"none\",\n",
        "          axis.text = element_text(size = 10),\n",
        "          axis.title = element_text(size = 11)) +\n",
        "    theme(axis.title.x = element_blank(),\n",
        "          axis.text.x = element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.text.y= element_blank(),\n",
        "          strip.text = element_text(size = 5)#, text=element_text(family=\"LM Sans 10\")\n",
        "          )\n",
        "\n",
        "\n",
        "# print(mcmc_trace_dependent_kf)\n",
        "\n",
        "# Append the dependent trace plot to the list of covariate trace plots\n",
        "mcmc_trace_list <- c(mcmc_trace_list, list(mcmc_trace_dependent_kf))\n",
        "\n",
        "# Combine all plots into a single grid layout using patchwork\n",
        "mcmc_trace_combined_kf <- wrap_plots(mcmc_trace_list, ncol = 3) +  # Adjust `ncol` for layout\n",
        "  plot_annotation(title = paste(\"KF trace plots \", time_range[1],\"-\", time_range[2]),\n",
        "                  theme = theme(plot.title = element_text(size = 25, hjust = .5))) #, family = \"LM Sans 10\"\n",
        "\n",
        "# Display the combined plot\n",
        "print(mcmc_trace_combined_kf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRlzNlcflwD-"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility when sampling x indices\n",
        "set.seed(123)\n",
        "\n",
        "# Get the number of `x` elements for both covariates and dependent models\n",
        "n_x_covariates <- dim(jags_model_result_covariates_list[[1]]$mcmc[[1]])[2]  # For covariates model\n",
        "n_x_dependent <- dim(jags_model_result_dependent$mcmc[[1]])[2]  # For dependent model\n",
        "\n",
        "# Randomly select 3 indices for x from each model\n",
        "random_x_indices_covariates <- sample(1:n_x_covariates, 3)\n",
        "random_x_indices_dependent <- sample(1:n_x_dependent, 3)\n",
        "\n",
        "# Define parameter names for the randomly selected x indices\n",
        "mcmc_trace_random_x_covariates <- paste0(\"x[\", random_x_indices_covariates, \"]\")\n",
        "mcmc_trace_random_x_dependent <- paste0(\"x_shrt[\", random_x_indices_dependent, \"]\")  # Use `x_shrt` for dependent model\n",
        "\n",
        "# Plot MCMC traces for the selected x indices for covariates model\n",
        "mcmc_trace_random_x_covariates_plots <- lapply(1:length(jags_model_result_covariates_list), function(i) {\n",
        "  mcmc_trace(jags_model_result_covariates_list[[i]]$mcmc, pars = mcmc_trace_random_x_covariates) +\n",
        "    ggtitle(paste(\"KF trace - Random indices (\", covariatenames[i], \")\")) +\n",
        "    theme(plot.title = element_text(size = 10, hjust = .5)) +\n",
        "    theme(legend.position = \"none\",\n",
        "          axis.text = element_text(size = 10),\n",
        "          axis.title = element_text(size = 11)) +\n",
        "    theme(axis.title.x = element_blank(),\n",
        "          axis.text.x = element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.text.y= element_blank(),\n",
        "          strip.text = element_text(size = 5)) #, text=element_text(family=\"LM Sans 10\")\n",
        "})\n",
        "\n",
        "# Combine covariates' plots into one layout\n",
        "mcmc_trace_random_x_covariates_combined <- wrap_plots(mcmc_trace_random_x_covariates_plots, ncol = 3) +\n",
        "  plot_annotation(title = paste(\"KF trace plots for random indices\", time_range[1],\"-\", time_range[2]),\n",
        "                  theme = theme(plot.title = element_text(size = 15, hjust = .5))) #, family=\"LM Sans 10\"\n",
        "\n",
        "# Plot MCMC traces for the selected x_shrt indices for dependent model\n",
        "mcmc_trace_random_x_dependent_plot <- mcmc_trace(jags_model_result_dependent$mcmc, pars = mcmc_trace_random_x_dependent) +\n",
        "  ggtitle(paste(\"KF trace - Random indices (\", data_to_forecast, \")\")) +\n",
        "  theme(plot.title = element_text(size = 10, hjust = .5)) +\n",
        "  theme(legend.position = \"none\",\n",
        "        axis.text = element_text(size = 10),\n",
        "        axis.title = element_text(size = 11)) +\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.text.y= element_blank(),\n",
        "        strip.text = element_text(size = 5)) #, text=element_text(family=\"LM Sans 10\")\n",
        "\n",
        "# Combine both covariates and dependent model plots\n",
        "combined_trace_plots_random_x <- mcmc_trace_random_x_covariates_combined + mcmc_trace_random_x_dependent_plot\n",
        "\n",
        "# Display the combined plot\n",
        "print(combined_trace_plots_random_x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_WBKENGxVxn"
      },
      "source": [
        "# Extract the KF results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTogpyLhxZOm"
      },
      "outputs": [],
      "source": [
        "# Extract the results\n",
        "results_covariates_kf <- as.mcmc(jags_model_result_covariates)\n",
        "x_samples_covariates_kf <- as.matrix(results_covariates_kf)\n",
        "\n",
        "# Extract the results\n",
        "results_dependent_kf <- as.mcmc(jags_model_result_dependent)\n",
        "x_samples_dependent_kf <- as.matrix(results_dependent_kf)\n",
        "\n",
        "# Define proxies and index prefixes\n",
        "proxy_names <- c(var_names, data_to_forecast)\n",
        "proxy_length <- 1:length(proxy_names)  # Assuming proxy indices follow this order\n",
        "\n",
        "# Initialize an empty list to store the data frames\n",
        "proxy_dfs <- list()\n",
        "\n",
        "# Loop through proxies and process\n",
        "for (i in proxy_length) {\n",
        "  if (i <= (length(proxy_names) - 1)) {\n",
        "    # Extract the MCMC list for the i-th proxy\n",
        "    mcmc_samples <- jags_model_result_covariates_list[[i]]$mcmc\n",
        "\n",
        "    # Combine MCMC samples across chains (if necessary)\n",
        "    combined_samples <- do.call(rbind, mcmc_samples)\n",
        "\n",
        "    # Filter columns that start with \"x\" (e.g., x[1], x[2], ...)\n",
        "    x_columns <- grep(\"^x\\\\[\", colnames(combined_samples), value = TRUE)\n",
        "    filtered_samples <- combined_samples[, x_columns]\n",
        "\n",
        "    # Initialize a matrix to store the summary stats for each time point\n",
        "    n_time_points <- ncol(filtered_samples)\n",
        "    summary_stats <- matrix(NA, nrow = n_time_points, ncol = 4)\n",
        "    colnames(summary_stats) <- c(\"median_kf\", \"lower_kf\", \"upper_kf\", \"sd_kf\")\n",
        "\n",
        "    # Loop through each time series (x[1], x[2], ...)\n",
        "    for (j in 1:n_time_points) {\n",
        "      # Compute the median, 2.5%, and 97.5% quantiles for the j-th time series\n",
        "      summary_stats[j, \"median_kf\"] <- median(filtered_samples[, j])\n",
        "      summary_stats[j, \"lower_kf\"] <- quantile(filtered_samples[, j], 0.025)\n",
        "      summary_stats[j, \"upper_kf\"] <- quantile(filtered_samples[, j], 0.975)\n",
        "      summary_stats[j, \"sd_kf\"] <- sd(filtered_samples[, j])\n",
        "    }\n",
        "\n",
        "    # Store the summary stats for the i-th proxy\n",
        "    proxy_dfs[[paste0(\"Proxy_\", i)]] <- summary_stats\n",
        "  } else {\n",
        "    # For dependent (different source, x_samples_dependent_kf)\n",
        "    proxy_indices <- grep(\"^x_shrt\", colnames(x_samples_dependent_kf))\n",
        "    x_proxy <- apply(x_samples_dependent_kf[, proxy_indices], 2, median)\n",
        "    x_proxy_lower <- apply(x_samples_dependent_kf[, proxy_indices], 2, quantile, 0.025)\n",
        "    x_proxy_upper <- apply(x_samples_dependent_kf[, proxy_indices], 2, quantile, 0.975)\n",
        "    x_proxy_sd <- apply(x_samples_dependent_kf[, proxy_indices], 2, sd)\n",
        "\n",
        "    # Create a dataframe and store it\n",
        "    proxy_df <- data.frame(proxy_indices, x_proxy, x_proxy_lower, x_proxy_upper, x_proxy_sd)\n",
        "    proxy_dfs[[data_to_forecast]] <- proxy_df\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "# Extend dependent to match the length of new_time by padding with NAs\n",
        "dependent_df <- proxy_dfs[[data_to_forecast]]  # Dynamically select based on data_to_forecast\n",
        "dependent_extended_df <- data.frame(\n",
        "  agekaBP_kf = new_time,  # Use the full length of new_time\n",
        "  median_kf = c(dependent_df[, 2], rep(NA, length(new_time) - length(new_time_shrt))),\n",
        "  upper_kf = c(dependent_df[, 4], rep(NA, length(new_time) - length(new_time_shrt))),\n",
        "  lower_kf = c(dependent_df[, 3], rep(NA, length(new_time) - length(new_time_shrt))),\n",
        "  sd_kf = c(dependent_df[, 5], rep(NA, length(new_time) - length(new_time_shrt)))\n",
        ")\n",
        "\n",
        "# Replace the original O18 or C13 data frame with the extended version\n",
        "proxy_dfs[[data_to_forecast]] <- dependent_extended_df\n",
        "\n",
        "# Combine data frames into one for plotting\n",
        "combined_plot_kf <- do.call(rbind, lapply(seq_along(proxy_names), function(i) {\n",
        "  # Handle proxies stored as matrices (Proxy_1, Proxy_2, etc.)\n",
        "  if (i <= (length(proxy_names) - 1)) {\n",
        "    proxy_df <- proxy_dfs[[paste0(\"Proxy_\", i)]]\n",
        "\n",
        "    # Create a data frame for the current proxy with relevant columns\n",
        "    data.frame(agekaBP_kf = new_time,  # Assuming 'new_time' is a vector with time points\n",
        "               value_kf = proxy_df[, \"median_kf\"],  # Median values\n",
        "               upper_kf = proxy_df[, \"upper_kf\"],  # Upper bound (97.5% quantile)\n",
        "               lower_kf = proxy_df[, \"lower_kf\"],  # Lower bound (2.5% quantile)\n",
        "               #lower_kf = proxy_df[, \"sd_kf\"],  # sd\n",
        "               variable = proxy_names[i])  # Proxy name for identification\n",
        "  } else {\n",
        "    # Handle O18 separately since it's stored as a data frame\n",
        "    dependent_plot_df <- proxy_dfs[[data_to_forecast]]\n",
        "\n",
        "    # Create a data frame for O18\n",
        "    data.frame(agekaBP_kf = dependent_plot_df$agekaBP_kf,\n",
        "               value_kf = dependent_plot_df$median_kf,\n",
        "               upper_kf = dependent_plot_df$upper_kf,\n",
        "               lower_kf = dependent_plot_df$lower_kf,\n",
        "               #sd_kf = o18_df$sd_kf,\n",
        "               variable = data_to_forecast)  # Name O18 explicitly\n",
        "  }\n",
        "}))\n",
        "\n",
        "\n",
        "# Dynamically adjust the factor levels based on the data_to_forecast\n",
        "combined_plot_kf$variable <- factor(combined_plot_kf$variable,\n",
        "                                    levels = c(var_names, data_to_forecast))\n",
        "\n",
        "# Assuming 'O18' or 'C13' is the last dataset in combined_plot_data\n",
        "combined_plot_data <- combined_plot_data %>%\n",
        "  mutate(color = ifelse(variable == data_to_forecast & agekaBP > (time_range[2] - kyrs_to_forecast), \"red\", \"black\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwosxLTkx09T"
      },
      "source": [
        "# Plot the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhjpqTTux5HS"
      },
      "outputs": [],
      "source": [
        "# Add a column to conditionally color the dependent data plot\n",
        "# Plotting data\n",
        "if (timescale == \"forwards\") {\n",
        "  combined_plot_data$color <- ifelse(combined_plot_data$variable == data_to_forecast & combined_plot_data$agekaBP < (time_range[2] + kyrs_to_forecast), \"red\", \"black\")\n",
        "} else {\n",
        "  combined_plot_data$color <- ifelse(combined_plot_data$variable == data_to_forecast & combined_plot_data$agekaBP > (time_range[2] - kyrs_to_forecast), \"red\", \"black\")\n",
        "}\n",
        "\n",
        "#options(warn=-1)\n",
        "\n",
        "if (timescale == \"forwards\") {\n",
        "  # Plot with facet_wrap and custom color\n",
        "  plot_result_kf <- ggplot(combined_plot_kf, aes(x = agekaBP_kf, y = value_kf)) +\n",
        "  geom_point(data = combined_plot_data, aes(x = agekaBP, y = value, color = color), size = 0.3) +\n",
        "  geom_line(aes(color = \"Filtered\"), linewidth = 0.5) +\n",
        "  geom_vline(xintercept = (time_range[2] + kyrs_to_forecast), linetype = \"dashed\", color = \"red\") +\n",
        "  facet_wrap(~ variable, scales = \"free_y\", ncol = 2) +\n",
        "  geom_ribbon(aes(ymin = lower_kf, ymax = upper_kf), fill = \"cyan\", alpha = 0.3, color = NA) +\n",
        "  scale_color_manual(values = c(\"black\", \"blue\", \"red\"),\n",
        "                     labels = c(\"Data\" = \"Data\", \"Filtered\" = \"KF data\")) +\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  labs(x = \"Age (ka BP)\", y = \"Value\") +\n",
        "  theme_bw() +\n",
        "  theme(\n",
        "    #text = element_text(family = \"LM Sans 10\"),\n",
        "    legend.position = \"none\",\n",
        "    strip.placement = \"outside\",\n",
        "    strip.text.y = element_text(angle = 0, hjust = 0, margin = margin(r = 10)),\n",
        "    axis.text.y.right = element_text(margin = margin(l = 10))\n",
        "  ) +\n",
        "  scale_fill_identity()\n",
        "} else {\n",
        "  # Plot with facet_wrap and custom color\n",
        "plot_result_kf <- ggplot(combined_plot_kf, aes(x = agekaBP_kf, y = value_kf)) +\n",
        "  geom_point(data = combined_plot_data, aes(x = agekaBP, y = value, color = color), size = 0.3) +\n",
        "  geom_line(aes(color = \"Filtered\"), linewidth = 0.5) +\n",
        "  geom_vline(xintercept = (time_range[2] - kyrs_to_forecast), linetype = \"dashed\", color = \"red\") +\n",
        "  facet_wrap(~ variable, scales = \"free_y\", ncol = 2) +\n",
        "  geom_ribbon(aes(ymin = lower_kf, ymax = upper_kf), fill = \"cyan\", alpha = 0.3, color = NA) +\n",
        "  scale_color_manual(values = c(\"black\", \"blue\", \"red\"),\n",
        "                     labels = c(\"Data\" = \"Data\", \"Filtered\" = \"KF data\")) +\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  labs(x = \"Age (ka BP)\", y = \"Value\") +\n",
        "  theme_bw() +\n",
        "  theme(\n",
        "    #text = element_text(family = \"LM Sans 10\"),\n",
        "    legend.position = \"none\",\n",
        "    strip.placement = \"outside\",\n",
        "    strip.text.y = element_text(angle = 0, hjust = 0, margin = margin(r = 10)),\n",
        "    axis.text.y.right = element_text(margin = margin(l = 10))\n",
        "  ) +\n",
        "  scale_fill_identity()\n",
        "}\n",
        "\n",
        "# Print the plot\n",
        "print(plot_result_kf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byxYjBA9Q5Hj"
      },
      "source": [
        "# Prepare data for the Jags regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkqDfV7nQ1aP"
      },
      "outputs": [],
      "source": [
        "# Change the names of proxies\n",
        "names(proxy_dfs)[1:length(var_names)] <- var_names\n",
        "\n",
        "# Create lists for median and sd values\n",
        "X <- list()\n",
        "X_sd <- list()\n",
        "for (var in var_names) {\n",
        "  X[[paste0(var, \"_median_kf\")]] <- proxy_dfs[[var]][, \"median_kf\"]\n",
        "  X_sd[[paste0(var, \"_sd_kf\")]] <- proxy_dfs[[var]][, \"sd_kf\"]\n",
        "}\n",
        "\n",
        "# Convert to data frames\n",
        "X_df <- as.data.frame(X)\n",
        "X_sd_df <- as.data.frame(X_sd)\n",
        "\n",
        "# Store original Y and Y_sd\n",
        "Y_original <- c(proxy_dfs[[data_to_forecast]][[\"median_kf\"]])\n",
        "Y_sd_original <- c(proxy_dfs[[data_to_forecast]][[\"sd_kf\"]])\n",
        "\n",
        "# Standardize X and Y\n",
        "X_mean <- colMeans(X_df, na.rm = TRUE)\n",
        "X_sd_val <- apply(X_df, 2, sd, na.rm = TRUE)\n",
        "Y_mean <- mean(Y_original, na.rm = TRUE)\n",
        "Y_sd_val <- sd(Y_original, na.rm = TRUE)\n",
        "\n",
        "# Create standardized versions\n",
        "X_std <- scale(X_df)\n",
        "X_sd_std <- sweep(X_sd_df, 2, X_sd_val, \"/\")\n",
        "Y_std <- (Y_original - Y_mean) / Y_sd_val\n",
        "Y_sd_std <- Y_sd_original / Y_sd_val\n",
        "\n",
        "# Prepare data for JAGS with standardized values\n",
        "data_list_ssvs <- list(\n",
        "  N = length(Y_std),\n",
        "  P = ncol(X_std),\n",
        "  Y = Y_std,\n",
        "  Y_sd = Y_sd_std,\n",
        "  X = as.matrix(X_std),\n",
        "  X_sd = as.matrix(X_sd_std),\n",
        "  n_predict = sum(is.na(Y_original))\n",
        ")\n",
        "\n",
        "# Initial values\n",
        "inits_regression <- function() {\n",
        "  list(beta = rnorm(P), gamma = rbinom(P, 1, 0.5), sigma_ss = runif(1, 0, 10), sigma_y = runif(1, 0, 10), sigma_x = runif(1, 0, 10))\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ3zqdlARQQ8"
      },
      "source": [
        "# Define the Jags function for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PEeG4ndRWYh"
      },
      "outputs": [],
      "source": [
        "ssvs_jags <- function(jags_data,\n",
        "                              n.chains = 3,\n",
        "                              burnin = 1000,\n",
        "                              adapt = 2000,\n",
        "                              sample = 3000,\n",
        "                              thin = 2,\n",
        "                              initlist = NA,\n",
        "                              model = c(\"simplyssvs\", \"rwlevel\", \"staticlevel\", \"ar1\")) {\n",
        "\n",
        "  # SSVS regression model\n",
        "  regression_model_with_simplyssvs <- \"\n",
        "model {\n",
        "    for (t in 1:(N-n_predict)) {\n",
        "        Y[t] ~ dnorm(mu[t], tau_y[t])\n",
        "        mu[t] <- inprod(X[t,], beta)\n",
        "        tau_y[t] <- 1/((Y_sd[t] + sigma_y)^2) # 1/(Y_sd[t]^2 + sigma_y^2)\n",
        "\n",
        "        for (j in 1:P) {\n",
        "            X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "            state[t,j] ~ dnorm(0, 0.01)  # More informative prior\n",
        "            tau_x[t,j] <- 1/((X_sd[t,j] + sigma_x)^2) # 1/(X_sd[t,j]^2 + sigma_x^2)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Prediction part remains similar but with modified precisions\n",
        "    for (t in (N-n_predict+1):N) {\n",
        "        Y[t] ~ dnorm(mu[t], 1/sigma_y^2)\n",
        "        mu[t] <- inprod(X[t,], beta)\n",
        "        loglik[t] <- logdensity.norm(Y[t], mu[t], 1/sigma_y^2)\n",
        "\n",
        "        for (j in 1:P) {\n",
        "            X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "            state[t,j] ~ dnorm(0, 0.1)\n",
        "            tau_x[t,j] <- 1/(X_sd[t,j] + sigma_x)^2\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (j in 1:P) {\n",
        "        beta[j] <- gamma[j]*delta[j]\n",
        "        gamma[j] ~ dbern(prob[j])\n",
        "        prob[j] ~ dbeta(1, 1)\n",
        "        delta[j] ~ dt(0, tau_ss, nu[j])\n",
        "        nu[j] ~ dexp(1/30)  # Modified rate\n",
        "    }\n",
        "\n",
        "    # Modified variance priors\n",
        "    tau_ss <- 1/sigma_ss^2\n",
        "    sigma_ss ~ dt(0,4^-2,1)T(0,) # dgamma(1, 0.1) #dgamma(2, 1)\n",
        "    sigma_y ~ dt(0,4^-2,1)T(0,) # dgamma(1, 0.1) #dgamma(2, 1)\n",
        "    sigma_x ~ dt(0,4^-2,1)T(0,) # dgamma(1, 0.1) #dgamma(2, 1)\n",
        "\n",
        "    # PPC\n",
        "    for (t in 1:(N-n_predict)) {\n",
        "        Y_rep[t] ~ dnorm(mu[t], tau_y[t])\n",
        "    }\n",
        "}\n",
        "\"\n",
        "\n",
        "\n",
        "#   # SSVS regression model\n",
        "#   regression_model_with_rw_level <- \"\n",
        "# model {\n",
        "#     for (t in 1:(N-n_predict)) {\n",
        "#         Y[t] ~ dnorm(mu[t], tau_y[t])\n",
        "#         mu[t] <- level[t] + inprod(X[t,], beta)\n",
        "#         tau_y[t] <- (Y_sd[t]^2 + (sigma_y)^2)^(-1)\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     for (t in (N-n_predict+1):N) {\n",
        "#         Y[t] ~ dnorm(mu[t], sigma_y^-2)\n",
        "#         mu[t] <- level[t] + inprod(X[t,], beta)\n",
        "#         loglik[t] <- logdensity.norm(Y[t], mu[t], sigma_y^-2)\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     for (j in 1:P) {\n",
        "#         beta[j] <- gamma[j]*delta[j]\n",
        "#         # gamma[j] ~ dbern(0.5)\n",
        "#         gamma[j] ~ dbern(prob[j])\n",
        "#         prob[j] ~ dbeta(1, 1)  # Uniform prior for prob\n",
        "#         delta[j] ~ dnorm(0, tau_ss)\n",
        "#     }\n",
        "#     level[1] ~ dnorm(0, 0.001)\n",
        "#     for (t in 2:N) {\n",
        "#         level[t] ~ dnorm(level[t-1], tau_lvl)\n",
        "#     }\n",
        "#     tau_ss <- pow(sigma_ss, -2)\n",
        "#     tau_lvl <- pow(sigma_lvl, -2)\n",
        "#     sigma_lvl ~ dt(0,4^-2,1)T(0,)\n",
        "#     sigma_ss ~ dnorm(0,10^-2)T(0,)\n",
        "#     sigma_y ~ dt(0,4^-2,1)T(0,)\n",
        "#     sigma_x ~ dt(0,4^-2,1)T(0,)\n",
        "# }\n",
        "# \"\n",
        "\n",
        "\n",
        "# regression_model_with_ar1 <- \"\n",
        "# model {\n",
        "#     for (t in 2:(N-n_predict)) {\n",
        "#         Y[t] ~ dnorm(mu[t], tau_y[t])\n",
        "#         mu[t] <- phi * Y[t-1] + inprod(X[t,], beta)\n",
        "#         tau_y[t] <- (Y_sd[t]^2 + (sigma_y)^2)^(-1)\n",
        "#         #loglik[t] <- logdensity.norm(Y[t], mu[t], tau_y[t])\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     for (t in (N-n_predict+1):N) {\n",
        "#         Y[t] ~ dnorm(mu[t], sigma_y^-2)\n",
        "#         mu[t] <- phi * Y[t-1] + inprod(X[t,], beta)\n",
        "#         loglik[t] <- logdensity.norm(Y[t], mu[t], sigma_y^-2)\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     phi ~ dnorm(0, 0.001)\n",
        "#     Y[1]~dnorm(0, 0.01)\n",
        "\n",
        "#     for (j in 1:P) {\n",
        "#         beta[j] <- gamma[j]*delta[j]\n",
        "#         # gamma[j] ~ dbern(0.5)\n",
        "#         gamma[j] ~ dbern(prob[j])\n",
        "#         prob[j] ~ dbeta(1, 1)  # Uniform prior for prob\n",
        "#         delta[j] ~ dnorm(0, tau_ss)\n",
        "#     }\n",
        "\n",
        "#     tau_ss <- pow(sigma_ss, -2)\n",
        "#     sigma_ss ~ dnorm(0,10^-2)T(0,)\n",
        "#     sigma_y ~ dt(0,4^-2,1)T(0,)\n",
        "#     sigma_x ~ dt(0,4^-2,1)T(0,)\n",
        "# }\n",
        "# \"\n",
        "\n",
        "# # SSVS regression model\n",
        "# regression_model_with_static_level <- \"\n",
        "# model {\n",
        "#     for (t in 1:(N-n_predict)) {\n",
        "#         Y[t] ~ dnorm(mu[t], tau_y[t])\n",
        "#         mu[t] <- level[t] + inprod(X[t,], beta)\n",
        "#         tau_y[t] <- (Y_sd[t]^2 + (sigma_y)^2)^(-1)\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     for (t in (N-n_predict+1):N) {\n",
        "#         Y[t] ~ dnorm(mu[t], sigma_y^-2)\n",
        "#         mu[t] <- level[t] + inprod(X[t,], beta)\n",
        "#         loglik[t] <- logdensity.norm(Y[t], mu[t], sigma_y^-2)\n",
        "#         for (j in 1:P) {\n",
        "#           X[t,j] ~ dnorm(state[t,j], tau_x[t,j])\n",
        "#           state[t,j] ~ dnorm(0, 0.001)\n",
        "#           tau_x[t,j] <- (X_sd[t,j]^2 + (sigma_x)^2)^(-1)\n",
        "#         }\n",
        "#     }\n",
        "#     for (j in 1:P) {\n",
        "#         beta[j] <- gamma[j]*delta[j]\n",
        "#         # gamma[j] ~ dbern(0.5)\n",
        "#         gamma[j] ~ dbern(prob[j])\n",
        "#         prob[j] ~ dbeta(1, 1)  # Uniform prior for prob\n",
        "#         delta[j] ~ dnorm(0, tau_ss)\n",
        "#     }\n",
        "#     for (t in 1:N) {\n",
        "#         level[t] ~ dnorm(0, tau_lvl)\n",
        "#     }\n",
        "#     tau_ss <- pow(sigma_ss, -2)\n",
        "#     tau_lvl <- pow(sigma_lvl, -2)\n",
        "#     sigma_lvl ~ dt(0,4^-2,1)T(0,)\n",
        "#     sigma_ss ~ dnorm(0,10^-2)T(0,)\n",
        "#     sigma_y ~ dt(0,4^-2,1)T(0,)\n",
        "#     sigma_x ~ dt(0,4^-2,1)T(0,)\n",
        "# }\n",
        "# \"\n",
        "\n",
        "\n",
        "  if (model == \"rwlevel\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"regression_model_with_rw_level.jags\"\n",
        "    writeLines(regression_model_with_rw_level, con = model)\n",
        "    parameters <- c(\"beta\", \"gamma\", \"delta\", \"sigma_ss\", \"sigma_y\", \"sigma_lvl\", \"level\", \"loglik\", \"sigma_x\", \"prob\", \"Y_rep\")\n",
        "  } else if (model == \"simplyssvs\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"regression_model_with_simplyssvs.jags\"\n",
        "    writeLines(regression_model_with_simplyssvs, con = model)\n",
        "    parameters <- c(\"beta\", \"gamma\", \"delta\", \"sigma_ss\", \"sigma_y\", \"loglik\", \"sigma_x\", \"prob\", \"Y_rep\")\n",
        "  } else if (model == \"ar1\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"regression_model_with_ar1.jags\"\n",
        "    writeLines(regression_model_with_ar1, con = model)\n",
        "    parameters <- c(\"beta\", \"gamma\", \"delta\", \"sigma_ss\", \"sigma_y\", \"phi\", \"loglik\", \"sigma_x\", \"prob\")\n",
        "  } else if (model == \"staticlevel\") {\n",
        "    # Write the model to a file\n",
        "    model <- \"regression_model_with_static_level.jags\"\n",
        "    writeLines(regression_model_with_static_level, con = model)\n",
        "    parameters <- c(\"beta\", \"gamma\", \"delta\", \"sigma_ss\", \"sigma_y\", \"sigma_lvl\", \"level\", \"loglik\", \"sigma_x\", \"prob\")\n",
        "  }\n",
        "\n",
        "\n",
        "  # Parameters to monitor\n",
        "  # parameters <- c(\"x_shrt\", \"sigma_proc_shrt\", \"sigma_obs_shrt\", \"sigma_age_shrt\")\n",
        "\n",
        "  # Run the JAGS model\n",
        "  jags_regression_model <- run.jags(\n",
        "    model = model,\n",
        "    data = jags_data,\n",
        "    monitor = parameters,\n",
        "    n.chains = n.chains,\n",
        "    burnin = burnin,\n",
        "    sample = sample,\n",
        "    adapt = adapt,\n",
        "    thin = thin,\n",
        "    #inits = initlist,\n",
        "    method = \"parallel\",\n",
        "    modules = c(\"glm\", \"dic\")\n",
        "  )\n",
        "\n",
        "  return(jags_regression_model)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiBtizP6RdFT"
      },
      "source": [
        "# Run the Jags regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU2briuDRcdK"
      },
      "outputs": [],
      "source": [
        "# Run the covariates model\n",
        "jags_regression_model <- ssvs_jags(\n",
        "  jags_data = data_list_ssvs,\n",
        "  n.chains = 3,\n",
        "  burnin = 5000,\n",
        "  adapt = 5000,\n",
        "  sample = 10000,\n",
        "  thin = 2,\n",
        "  initlist = inits_regression,\n",
        "  model = mymodel\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rLMyDaoLc6U"
      },
      "source": [
        "# In case it did not converge, to extend the runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TkPl_DWn47Dt"
      },
      "outputs": [],
      "source": [
        "  # Convert to coda object for diagnostics\n",
        "  coda_samples_regression <- as.mcmc.list(jags_regression_model)\n",
        "\n",
        "  # Compute Gelman-Rubin statistic\n",
        "  gelman_result_regression <- tryCatch(gelman.diag(coda_samples_regression), error = function(e) NULL)\n",
        "\n",
        "  if (!is.null(gelman_result_dependent)) {\n",
        "    # Extract max potential scale reduction factor (PSRF)\n",
        "    max_psrf <- max(gelman_result_regression$psrf[, 1], na.rm = TRUE)\n",
        "\n",
        "    if (max_psrf > 1.1) {  # Common threshold for non-convergence\n",
        "      print(paste(\"Extending run for proxy due to poor convergence (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "\n",
        "      # Extend the MCMC run\n",
        "      extended_results <- extend.JAGS(jags_regression_model,\n",
        "                                      burnin = 0,\n",
        "                                      sample = 20000)\n",
        "\n",
        "      # Update stored results\n",
        "      jags_regression_model <- extended_results\n",
        "\n",
        "      print(paste(\"Extended run for regression\"))\n",
        "    } else {\n",
        "      print(paste(\"Proxy has converged (max PSRF:\", round(max_psrf, 3), \")\"))\n",
        "    }\n",
        "  } else {\n",
        "    print(paste(\"Gelman diagnostic failed for regression\"))\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCFbeM_SeBF"
      },
      "source": [
        "# Extract posterior samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDGUx1mwSlK7"
      },
      "outputs": [],
      "source": [
        "# Extract and process posterior samples\n",
        "samples <- as.mcmc.list(jags_regression_model)\n",
        "beta_samples <- as.matrix(samples[, grep(\"beta\", varnames(samples))])\n",
        "loglik_samples <- as.matrix(samples[, grep(\"loglik\", varnames(samples))])\n",
        "\n",
        "# Generate predictions in standardized scale\n",
        "X_matrix_std <- as.matrix(X_std)\n",
        "Y_pred_std_samples <- beta_samples %*% t(X_matrix_std)\n",
        "\n",
        "# Back-transform predictions to original scale\n",
        "Y_pred_samples <- sweep(Y_pred_std_samples, 2, Y_sd_val, \"*\")\n",
        "Y_pred_samples <- sweep(Y_pred_samples, 2, Y_mean, \"+\")\n",
        "\n",
        "# Back-transform beta coefficients to original scale\n",
        "beta_original_scale <- sweep(beta_samples, 2, Y_sd_val/X_sd_val, \"*\")\n",
        "\n",
        "# Create summary dataframes\n",
        "df_beta <- data.frame(\n",
        "  Predictor = names(X),\n",
        "  Mean = colMeans(beta_original_scale),\n",
        "  CI_Lower = apply(beta_original_scale, 2, quantile, probs = 0.055),\n",
        "  CI_Upper = apply(beta_original_scale, 2, quantile, probs = 0.945)\n",
        ")\n",
        "\n",
        "# Calculate prediction summaries\n",
        "Y_pred_summary <- data.frame(\n",
        "  Mean = apply(Y_pred_samples, 2, mean),\n",
        "  Median = apply(Y_pred_samples, 2, median),\n",
        "  SD = apply(Y_pred_samples, 2, sd),\n",
        "  CI_Lower = apply(Y_pred_samples, 2, quantile, probs = 0.055),\n",
        "  CI_Upper = apply(Y_pred_samples, 2, quantile, probs = 0.945)\n",
        ")\n",
        "\n",
        "  # Plot beta coefficients\n",
        "  plot_beta <- ggplot(df_beta, aes(x = Predictor)) +\n",
        "    geom_point(aes(y = Mean), color = \"red\") +\n",
        "    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.2, color = \"red\") +\n",
        "    labs(title = \"Back-transformed Beta Coefficients\",\n",
        "         x = \"Predictor\",\n",
        "         y = \"Beta\") +\n",
        "    theme_minimal()\n",
        "\n",
        "  # Save the beta plot\n",
        "  ggsave(plot_beta,\n",
        "         filename = \"beta_coefficients_backtransformed.pdf\",\n",
        "         device = \"pdf\",\n",
        "         height = 10, width = 10, units = \"in\")\n",
        "\n",
        "  # Print the beta plot\n",
        "  print(plot_beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KWOFNocT6tU"
      },
      "source": [
        "# Plotting the regression results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMx1bjABT9WT"
      },
      "outputs": [],
      "source": [
        "# Calculate summary statistics\n",
        "Y_pred_median <- apply(Y_pred_samples, 2, median)\n",
        "Y_pred_sd <- apply(Y_pred_samples, 2, sd)\n",
        "Y_pred_ci <- apply(Y_pred_samples, 2, quantile, probs = c(0.005, 0.975))\n",
        "\n",
        "# Print summary statistics for Y_pred\n",
        "Y_pred_summary <- data.frame(\n",
        "  Mean = Y_pred_median,\n",
        "  SD = Y_pred_sd,\n",
        "  CI_Lower = Y_pred_ci[1, ],\n",
        "  CI_Upper = Y_pred_ci[2, ]\n",
        ")\n",
        "\n",
        "# Cropping O18 data to the specified date range\n",
        "# Create cropped datasets with dynamic names\n",
        "if (timescale == \"forwards\") {\n",
        "  dependent_ssvs_cropped <- data_variable[data_variable$agekaBP < (time_range[1]) & data_variable$agekaBP > time_range[2], ]\n",
        "} else {\n",
        "  dependent_ssvs_cropped <- data_variable[data_variable$agekaBP < time_range[2] & data_variable$agekaBP > time_range[1], ]\n",
        "}\n",
        "\n",
        "\n",
        "plot_data <- list(\n",
        "  predicteddata=data.frame(\n",
        "    Time = 1:N,\n",
        "    TimekaBP = proxy_dfs[[data_to_forecast]][[\"agekaBP_kf\"]],\n",
        "    Observed = proxy_dfs[[data_to_forecast]][[\"median_kf\"]],\n",
        "    Predicted = Y_pred_median,\n",
        "    Lower = Y_pred_ci[1, ],\n",
        "    Upper = Y_pred_ci[2, ]),\n",
        "  observeddata=data.frame(\n",
        "    data_to_predict = dependent_ssvs_cropped[[data_to_forecast]],\n",
        "    age_data_to_predict = dependent_ssvs_cropped$agekaBP\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "if (timescale == \"forwards\") {\n",
        "  ssvs_result <- ggplot(plot_data$predicteddata, aes(x = Time)) +\n",
        "    theme(legend.position = \"right\") +  # Removing the plot.title element\n",
        "    geom_point(data=plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\")) + # , linewidth = 0.5\n",
        "    #geom_line(aes(x = seq(time_range[1],(time_range[2]), by=0.1), y = Observed, color = \"Observed\"), linewidth = 1) +\n",
        "    geom_line(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), y = Predicted, color = \"Predicted\"), linewidth = 0.75) +\n",
        "    geom_ribbon(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), ymin = Lower, ymax = Upper, fill = \"Prediction Interval\"), alpha = 0.5) +\n",
        "    geom_point(data = plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\"), alpha = 1, size = 1) +\n",
        "    geom_point(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), y = Predicted, color = \"Predicted\"), size = 1) +\n",
        "    geom_vline(xintercept=(time_range[2] + kyrs_to_forecast), linetype=\"dashed\", color = \"red\") +\n",
        "    ggtitle(paste(\"Observed and predicted\", data_to_forecast)) +\n",
        "    theme(plot.title = element_text(size = 20, hjust = .5)) +\n",
        "    labs(y = data_to_forecast,\n",
        "         x = \"age (ka BP)\",\n",
        "         color = NULL,\n",
        "         fill = NULL) +  # Remove legend titles for color and fill\n",
        "    scale_color_manual(values = c(\"Observed\" = \"red\", \"Predicted\" = \"blue\", \"Data\" = \"black\"),\n",
        "                       labels = c(\"Observed\" = \"KF regression\", \"Predicted\" = \"Predicted\")) +\n",
        "    scale_fill_manual(values = \"cyan\") +\n",
        "    theme_light() #+\n",
        "    #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "} else {\n",
        "  ssvs_result <- ggplot(plot_data$predicteddata, aes(x = Time)) +\n",
        "    theme(legend.position = \"right\") +  # Removing the plot.title element\n",
        "    geom_point(data=plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\")) + #, linewidth = 0.5\n",
        "    #geom_line(aes(x = seq(time_range[1],(time_range[2]), by=0.1), y = Observed, color = \"Observed\"), linewidth = 1) +\n",
        "    geom_line(aes(x = seq(time_range[1],(time_range[2]), by=resolution), y = Predicted, color = \"Predicted\"), linewidth = 0.75) +\n",
        "    geom_ribbon(aes(x = seq(time_range[1],(time_range[2]), by=resolution), ymin = Lower, ymax = Upper, fill = \"Prediction Interval\"), alpha = 0.5) +\n",
        "    geom_point(data = plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\"), alpha = 1, size = 1) +\n",
        "    geom_point(aes(x = seq(time_range[1],(time_range[2]), by=resolution), y = Predicted, color = \"Predicted\"), size = 1) +\n",
        "    geom_vline(xintercept=(time_range[2] - kyrs_to_forecast), linetype=\"dashed\", color = \"red\") +\n",
        "    ggtitle(paste(\"Observed and predicted\", data_to_forecast)) +\n",
        "    theme(plot.title = element_text(size = 20, hjust = .5)) +\n",
        "    labs(y = data_to_forecast,\n",
        "         x = \"age (ka BP)\",\n",
        "         color = NULL,\n",
        "         fill = NULL) +  # Remove legend titles for color and fill\n",
        "    scale_color_manual(values = c(\"Observed\" = \"red\", \"Predicted\" = \"blue\", \"Data\" = \"black\"),\n",
        "                       labels = c(\"Observed\" = \"KF regression\", \"Predicted\" = \"Predicted\")) +\n",
        "    scale_fill_manual(values = \"cyan\") +\n",
        "    theme_light() #+\n",
        "    #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "print(ssvs_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AziX28CTrBYw"
      },
      "source": [
        "# Posterior predictive check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIyS3zAUrB7j"
      },
      "outputs": [],
      "source": [
        "# Extract Y_rep samples from JAGS output\n",
        "Y_rep_samples <- as.matrix(samples[, grep(\"Y_rep\", varnames(samples))])\n",
        "\n",
        "# Back-transform Y_rep samples to original scale\n",
        "Y_rep_original1 <- sweep(Y_rep_samples, 2, Y_sd_val, \"*\")\n",
        "Y_rep_original <- sweep(Y_rep_original1, 2, Y_mean, \"+\")\n",
        "\n",
        "# Create data frame for plotting\n",
        "ppc_data <- data.frame(\n",
        "  Observed = Y_original[!is.na(Y_original)],  # Remove NA values\n",
        "  Replicated = apply(Y_rep_original, 2, mean)  # Take first replicate for density plot\n",
        ")\n",
        "\n",
        "# Create PPC plot\n",
        "ppc_y_afterssvs <- ggplot() +\n",
        "  geom_density(data = ppc_data, aes(x = Observed, fill = \"Observed\"),\n",
        "              alpha = 0.3) +\n",
        "  geom_density(data = data.frame(y = as.vector(Y_rep_original)),\n",
        "               aes(x = y, fill = \"Replicated\"),\n",
        "               alpha = 0.3) +\n",
        "  scale_fill_manual(values = c(\"Observed\" = \"blue\", \"Replicated\" = \"red\"),\n",
        "                    name = \"Data\") +\n",
        "  labs(x = \"Values\",\n",
        "       y = \"Density\",\n",
        "       title = \"Posterior Predictive Check\",\n",
        "       subtitle = \"Observed vs. Replicated Data\") +\n",
        "  theme_light() +\n",
        "  theme(#text = element_text(family = \"LM Sans 10\"),\n",
        "        legend.position = \"bottom\")\n",
        "\n",
        "# Optional: Add numerical summary\n",
        "ppc_summary <- data.frame(\n",
        "  Statistic = c(\"Mean\", \"SD\", \"25th Percentile\", \"Median\", \"75th Percentile\"),\n",
        "  Observed = c(\n",
        "    mean(ppc_data$Observed),\n",
        "    sd(ppc_data$Observed),\n",
        "    quantile(ppc_data$Observed, 0.25),\n",
        "    median(ppc_data$Observed),\n",
        "    quantile(ppc_data$Observed, 0.75)\n",
        "  ),\n",
        "  Replicated = c(\n",
        "    mean(as.vector(Y_rep_original)),\n",
        "    sd(as.vector(Y_rep_original)),\n",
        "    quantile(as.vector(Y_rep_original), 0.25),\n",
        "    median(as.vector(Y_rep_original)),\n",
        "    quantile(as.vector(Y_rep_original), 0.75)\n",
        "  )\n",
        ")\n",
        "\n",
        "# Print plot and summary\n",
        "print(ppc_y_afterssvs)\n",
        "print(ppc_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwaY1m-4zgDL"
      },
      "source": [
        "# Convergence check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL6VXM37zjco"
      },
      "outputs": [],
      "source": [
        "# Trace and histogram plots\n",
        "mcmc_trace_ssvs <- mcmc_trace(jags_regression_model$mcmc, pars =  c(\"sigma_ss\", \"sigma_y\", \"sigma_x\")) + #, \"sigma_x\"\n",
        "  ggtitle(paste(\"SSVS Regression\", time_range[1],\"-\", time_range[2])) +\n",
        "  theme_light() +\n",
        "  #theme(text=element_text(family=\"LM Sans 10\")) +\n",
        "  theme(plot.title = element_text(size = 20, hjust = .5)) +\n",
        "  theme(legend.position=\"none\", axis.text = element_text(size = 10), axis.title = element_text(size = 11)) +\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.text.y= element_blank())\n",
        "\n",
        "print(mcmc_trace_ssvs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAWTRRtq5zk6"
      },
      "outputs": [],
      "source": [
        "# Get the total number of beta parameters\n",
        "n_beta <- length(covariatenames)\n",
        "\n",
        "# Generate parameter names for all beta parameters\n",
        "beta_parameters <- paste0(\"beta[\", 1:n_beta, \"]\")\n",
        "\n",
        "# Loop through all beta parameters and create density plots\n",
        "mcmc_density_beta_list <- lapply(1:n_beta, function(i) {\n",
        "  mcmc_dens_overlay(jags_regression_model$mcmc, pars = beta_parameters[i]) +\n",
        "    ggtitle(paste(\"Density plot for\", covariatenames[i])) +\n",
        "    theme(plot.title = element_text(size = 10, hjust = .5)) +\n",
        "    theme(legend.position = \"none\",\n",
        "          axis.text = element_text(size = 8),\n",
        "          axis.title = element_text(size = 9)) #+\n",
        "    #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "})\n",
        "\n",
        "# Combine all plots into a single layout using patchwork\n",
        "mcmc_density_beta_combined <- wrap_plots(mcmc_density_beta_list, ncol = 4) +\n",
        "  plot_annotation(title = \"Density plots for Beta parameters\",\n",
        "                  theme = theme(plot.title = element_text(size = 15, hjust = .5))) #, family=\"LM Sans 10\"\n",
        "\n",
        "# Display the combined plot\n",
        "print(mcmc_density_beta_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQidasa5UD9J"
      },
      "source": [
        "# Plotting the inclusion probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSLaL0wvUHPS"
      },
      "outputs": [],
      "source": [
        "# Remove \"_mean\" from the column names\n",
        "names_without_mean <- gsub(\"_mean\", \"\", names(X))\n",
        "\n",
        "rename_elements <- function(name) {\n",
        "  # Split the name by \"[\" to get the prefix and index\n",
        "  parts <- unlist(strsplit(name, \"\\\\[\"))\n",
        "  prefix <- parts[1]\n",
        "  index <- parts[2]\n",
        "  index <- substr(index, 1, nchar(index) - 1)  # Remove the closing bracket\n",
        "\n",
        "  # Create the new name based on the prefix and index\n",
        "  new_name <- paste(prefix, names_without_mean[as.numeric(index)], sep = \".\")\n",
        "  return(new_name)\n",
        "}\n",
        "\n",
        "# Get the summary of the model_run_ssvs\n",
        "model_summary <- summary(jags_regression_model)\n",
        "\n",
        "# Get the row names of the summary object\n",
        "rownames_summary <- rownames(model_summary)\n",
        "\n",
        "# Rename each row name\n",
        "new_row_names <- sapply(rownames_summary, rename_elements)\n",
        "\n",
        "\n",
        "# Assign the new row names to the summary object\n",
        "rownames(model_summary) <- new_row_names\n",
        "\n",
        "# Print the modified summary\n",
        "#print(model_summary)\n",
        "\n",
        "# Extract gamma means from the model summary\n",
        "gamma_means <- model_summary[grep(\"^gamma\", rownames(model_summary)), \"Mean\"]\n",
        "gamma_names <- names_without_mean\n",
        "#\n",
        "\n",
        "# Create a data frame for ggplot\n",
        "gamma_data <- data.frame(gamma_index = gamma_names, mean_value = gamma_means)\n",
        "\n",
        "gamma_data$gamma_label <- sub(\"_median_kf$\", \"\", gamma_data$gamma_index)  # Remove \"_median_kf\" suffix\n",
        "\n",
        "# Set factor levels for gamma_label to preserve the dataset order\n",
        "gamma_data$gamma_label <- factor(gamma_data$gamma_label, levels = gamma_data$gamma_label)\n",
        "\n",
        "# Plot using ggplot\n",
        "incl_prob <- ggplot(gamma_data, aes(x = gamma_label, y = mean_value)) +\n",
        "  geom_bar(stat = \"identity\") +\n",
        "  labs(title = data_to_forecast,\n",
        "       x = \"Gamma Index\",\n",
        "       y = \"Inclusion probability\") +\n",
        "  ylim(0, 1) +\n",
        "  theme(axis.text.x = element_text(angle = 45, hjust = 1)#+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "  ) +\n",
        "    theme_light()\n",
        "\n",
        "print(incl_prob)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxg2csdVUVsS"
      },
      "source": [
        "# Save the plots and the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcOqEW2ZUmCe"
      },
      "outputs": [],
      "source": [
        "\n",
        "ggsave(plotraw,\n",
        "       filename = paste(\"raw_data_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 10, width = 10, units = \"in\")\n",
        "\n",
        "ggsave(mcmc_trace_covariates_kf,\n",
        "       filename = paste(\"KF_covariate_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 5, width = 8, units = \"in\")\n",
        "\n",
        "\n",
        "ggsave(mcmc_trace_dependent_kf,\n",
        "       filename = paste(\"KF_dependent_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 3, width = 7.5, units = \"in\")\n",
        "\n",
        "ggsave(plot_result_kf,\n",
        "       filename = paste(\"KF_results_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 10, width = 10, units = \"in\")\n",
        "\n",
        "ggsave(combined_trace_plots,\n",
        "       filename = paste(\"KF_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 6, width = 8, units = \"in\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpgS2E8vXU2h"
      },
      "outputs": [],
      "source": [
        "\n",
        "ggsave(incl_prob,\n",
        "       filename = paste(\"incl_prob_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 4, width = 10, units = \"in\")\n",
        "\n",
        "ggsave(ssvs_result,\n",
        "       filename = paste(\"ssvs_result_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 5, width = 7.5, units = \"in\")\n",
        "\n",
        "ggsave(ssvs_trace,\n",
        "       filename = paste(\"ssvs_trace_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 3, width = 7.5, units = \"in\")\n",
        "\n",
        "ggsave(mcmc_density_beta_combined,\n",
        "       filename = paste(\"mcmc_density_beta_combined_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 5, width = 8, units = \"in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g_xSL6NPYRL"
      },
      "outputs": [],
      "source": [
        "\n",
        "  file1 <- paste(\"raw_data_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file2 <- paste(\"KF_covariate_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file3 <- paste(\"KF_dependent_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file4 <- paste(\"KF_results_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file5 <- paste(\"KF_trace_\", data_to_forecast,\"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  file6 <- paste(\"incl_prob_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file7 <- paste(\"ssvs_result_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file8 <- paste(\"ssvs_trace_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n",
        "\n",
        "  file9 <- paste(\"mcmc_density_beta_combined_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i64nnMmcEqes"
      },
      "source": [
        "# Correlation of the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCtGhIF2EqJ9"
      },
      "outputs": [],
      "source": [
        "# Read data\n",
        "LR04_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/\",\n",
        "  \"refs/heads/main/Data/otherdata/LR04.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "chinastack_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/\",\n",
        "  \"refs/heads/main/Data/otherdata/chinastack.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "medstack_data_url_text <- paste(\n",
        "  \"https://raw.githubusercontent.com/\",\n",
        "  \"zboraon/proxy_impuation_SSVS/\",\n",
        "  \"refs/heads/main/Data/otherdata/medstack.csv\",\n",
        "  sep = \"\"\n",
        ")\n",
        "\n",
        "LR04_url <- getURL(LR04_data_url_text)\n",
        "chinastack_url <- getURL(chinastack_data_url_text)\n",
        "medstack_url <- getURL(medstack_data_url_text)\n",
        "\n",
        "# Load data\n",
        "LR04 <- read.csv(text = LR04_url)\n",
        "medstack <- read.csv(text = medstack_url)\n",
        "medstack_O18 <- medstack %>%\n",
        "  select(time_medstack, O18_medstack)\n",
        "medstack_C13 <- medstack %>%\n",
        "  select(time_medstack, C13_medstack)\n",
        "chinesestack <- read.csv(text = chinastack_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn0E5WIUImAk"
      },
      "outputs": [],
      "source": [
        "x_limits <- c()\n",
        "if (timescale == \"forwards\") {\n",
        "  x_limits[1] <- time_range[2]%/%10*10\n",
        "  x_limits[2] <- time_range[1]%/%10*10+10\n",
        "  verticalline <- time_range[2] + kyrs_to_forecast\n",
        "} else if (timescale == \"backwards\") {\n",
        "  x_limits[1] <- time_range[1]%/%10*10\n",
        "  x_limits[2] <- time_range[2]%/%10*10+10\n",
        "  verticalline <- time_range[2] - kyrs_to_forecast\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LR04_cropped <- LR04[LR04$time_lr04 >= min(time_range) & LR04$time_lr04 <= max(time_range), ]\n",
        "medstack_O18_cropped <- medstack_O18[medstack_O18$time_medstack >= min(time_range) & medstack_O18$time_medstack <= max(time_range), ]\n",
        "medstack_C13_cropped <- medstack_C13[medstack_C13$time_medstack >= min(time_range) & medstack_C13$time_medstack <= max(time_range), ]\n",
        "chinesestack_cropped <- chinesestack[chinesestack$age_chinastack >= min(time_range) & chinesestack$age_chinastack <= max(time_range), ]\n",
        "\n",
        "\n",
        "# Plot without titles, limit x-axis, and remove x-axis labels for the first two plots\n",
        "p1 <- ggplot(LR04_cropped, aes(x = time_lr04, y = O18_lr04)) +\n",
        "  geom_line() +\n",
        "  labs(y = \"O18_lr04\", x = NULL) +\n",
        "  # xlim(x_limits[1], x_limits[2]) +\n",
        "  # scale_y_reverse() +\n",
        "  #ylim(5, 3) +\n",
        "  theme_minimal() +\n",
        "  geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "  theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "  theme(  panel.grid.major.y = element_blank(),\n",
        "          panel.grid.minor.y = element_blank(),\n",
        "          panel.border = element_blank()) +\n",
        "  scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) + # Only one scale for x\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  scale_y_reverse( ) + # Combine reverse and position limits = c(2.6, -1.2),\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(),\n",
        "        axis.ticks.x = element_blank(),\n",
        "        plot.margin = margin(0, 0, 0, 0)) #+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "\n",
        "p2 <- ggplot(medstack_O18_cropped, aes(x = time_medstack, y = O18_medstack)) +\n",
        "  geom_line() +\n",
        "  labs(y = \"O18_medstack\", x = NULL) +\n",
        "  # xlim(x_limits[1], x_limits[2]) +\n",
        "  # scale_y_reverse() +\n",
        "  #ylim(2.6, -1.2) +\n",
        "  theme_minimal() +\n",
        "  geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "  theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "  theme(  panel.grid.major.y = element_blank(),\n",
        "          panel.grid.minor.y = element_blank(),\n",
        "          panel.border = element_blank()) +\n",
        "  scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) + # Only one scale for x\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  scale_y_reverse( position = \"right\") + # Combine reverse and position limits = c(2.6, -1.2),\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(),\n",
        "        axis.ticks.x = element_blank(),\n",
        "        axis.title.y.left = element_blank(),\n",
        "        axis.text.y.right = element_text(hjust = 1),\n",
        "        #axis.title.y.right = element_blank(),\n",
        "        plot.margin = margin(0, 0, 0, 0)) #+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "\n",
        "p3 <- ggplot(medstack_C13_cropped, aes(x = time_medstack, y = C13_medstack)) +\n",
        "  geom_line() +\n",
        "  labs(y = \"C13_medstack\", x = NULL) +\n",
        "  # xlim(x_limits[1], x_limits[2]) +\n",
        "  # scale_y_reverse() +\n",
        "  #ylim(2.6, -1.2) +\n",
        "  theme_minimal() +\n",
        "  geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "  theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "  theme(  panel.grid.major.y = element_blank(),\n",
        "          panel.grid.minor.y = element_blank(),\n",
        "          panel.border = element_blank()) +\n",
        "  scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) + # Only one scale for x\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  scale_y_reverse( ) + # Combine reverse and position limits = c(2.6, -1.2),\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(),\n",
        "        axis.ticks.x = element_blank(),\n",
        "        plot.margin = margin(0, 0, 0, 0)) #+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "\n",
        "p4 <- ggplot(chinesestack_cropped, aes(x = age_chinastack, y = O18_chinastack)) +\n",
        "  geom_line() +\n",
        "  labs(y = \"O18_chinastack\", x = \"Time\") +\n",
        "  # xlim(x_limits[1], x_limits[2]) +\n",
        "  # scale_y_reverse() +\n",
        "  #ylim(-5, -11.5) +\n",
        "  theme_minimal() +\n",
        "  geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "  theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "  theme(  panel.grid.major.y = element_blank(),\n",
        "          panel.grid.minor.y = element_blank(),\n",
        "          panel.border = element_blank()) +\n",
        "  scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) + # Only one scale for x\n",
        "  scale_y_continuous(n.breaks = 3)+\n",
        "  scale_y_reverse( position = \"right\") + # Combine reverse and position limits = c(2.6, -1.2),\n",
        "  theme(axis.title.x = element_blank(),\n",
        "        axis.text.x = element_blank(),\n",
        "        axis.ticks.x = element_blank(),\n",
        "        axis.title.y.left = element_blank(),\n",
        "        axis.text.y.right = element_text(hjust = 1),\n",
        "        #axis.title.y.right = element_blank(),\n",
        "        plot.margin = margin(0, 0, 0, 0)) #+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "\n",
        "if (timescale == \"forwards\") {\n",
        "  p5 <- ggplot(plot_data$predicteddata, aes(x = Time)) +\n",
        "    theme(#text = element_text(family = \"LM Sans 10\"),\n",
        "          legend.position = \"right\") +  # Removing the plot.title element\n",
        "    geom_point(data=plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\")) + #, linewidth = 0.5) +\n",
        "    #geom_line(aes(x = seq(time_range[1],(time_range[2]), by=0.1), y = Observed, color = \"Observed\"), linewidth = 1) +\n",
        "    geom_line(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), y = Predicted, color = \"Predicted\"), linewidth = 0.75) +\n",
        "    geom_ribbon(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), ymin = Lower, ymax = Upper, fill = \"Prediction Interval\"), alpha = 0.5) +\n",
        "    geom_point(data = plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\"), alpha = 1, size = 1) +\n",
        "    geom_point(aes(x = seq(time_range[1],(time_range[2]), by=-resolution), y = Predicted, color = \"Predicted\"), size = 1) +\n",
        "    geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "    #ggtitle(\"Observed and predicted O-18\") +\n",
        "    scale_y_reverse() +  # Remove the limits here\n",
        "    coord_cartesian(ylim = c()) +  # Add this line to clip instead of remove\n",
        "    scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) +\n",
        "    #xlim(x_limits[1], x_limits[2]) +\n",
        "    #ylim(6,-4) +\n",
        "    theme_minimal() +\n",
        "\n",
        "    theme(plot.title = element_text(size = 20, hjust = .5)) +\n",
        "    theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "    theme(  panel.grid.major.y = element_blank(),\n",
        "            panel.grid.minor.y = element_blank(),\n",
        "            panel.border = element_blank()) +\n",
        "    labs(y = data_to_forecast,\n",
        "         x = \"age (ka BP)\",\n",
        "         color = NULL,\n",
        "         fill = NULL) +  # Remove legend titles for color and fill\n",
        "    scale_color_manual(values = c(\"Observed\" = \"red\", \"Predicted\" = \"blue\", \"Data\" = \"black\"),\n",
        "                       labels = c(\"Observed\" = \"KF regression\", \"Predicted\" = \"Predicted\")) +\n",
        "    scale_fill_manual(values = \"cyan\") +\n",
        "\n",
        "    theme(plot.margin = margin(0, 0, 0, 0)) #+\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "} else {\n",
        "  p5 <- ggplot(plot_data$predicteddata, aes(x = Time)) +\n",
        "    theme(#text = element_text(family = \"LM Sans 10\"),\n",
        "          legend.position = \"right\") +  # Removing the plot.title element\n",
        "    geom_point(data=plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\")) + #, linewidth = 0.5) +\n",
        "    #geom_line(aes(x = seq(time_range[1],(time_range[2]), by=0.1), y = Observed, color = \"Observed\"), linewidth = 1) +\n",
        "    geom_line(aes(x = seq(time_range[1],(time_range[2]), by=resolution), y = Predicted, color = \"Predicted\"), linewidth = 0.75) +\n",
        "    geom_ribbon(aes(x = seq(time_range[1],(time_range[2]), by=resolution), ymin = Lower, ymax = Upper, fill = \"Prediction Interval\"), alpha = 0.5) +\n",
        "    geom_point(data = plot_data$observeddata, aes(x = age_data_to_predict, y = data_to_predict, color = \"Data\"), alpha = 1, size = 1) +\n",
        "    geom_point(aes(x = seq(time_range[1],(time_range[2]), by=resolution), y = Predicted, color = \"Predicted\"), size = 1) +\n",
        "    geom_vline(xintercept=verticalline, linetype=\"dashed\", color = \"red\") +\n",
        "    #ggtitle(\"Observed and predicted O-18\") +\n",
        "    scale_y_reverse() +  # Remove the limits here\n",
        "    coord_cartesian(ylim = c()) +  # Add this line to clip instead of remove\n",
        "    scale_x_continuous(breaks = seq(x_limits[1], x_limits[2], 10), limits = x_limits) +\n",
        "    #xlim(x_limits[1], x_limits[2]) +\n",
        "    # ylim(5,-5) +\n",
        "    theme_minimal() +\n",
        "\n",
        "    theme(plot.title = element_text(size = 20, hjust = .5)) +\n",
        "    theme(plot.margin = margin(0, 0, 0, 0)) +\n",
        "    theme(  panel.grid.major.y = element_blank(),\n",
        "            panel.grid.minor.y = element_blank(),\n",
        "              panel.border = element_blank()) +\n",
        "    labs(y = data_to_forecast,\n",
        "         x = \"age (ka BP)\",\n",
        "         color = NULL,\n",
        "         fill = NULL) +  # Remove legend titles for color and fill\n",
        "    scale_color_manual(values = c(\"Observed\" = \"red\", \"Predicted\" = \"blue\", \"Data\" = \"black\"),\n",
        "                       labels = c(\"Observed\" = \"KF regression\", \"Predicted\" = \"Predicted\")) +\n",
        "    scale_fill_manual(values = \"cyan\") +\n",
        "\n",
        "    theme(plot.margin = margin(0, 0, 0, 0)) # +\n",
        "  #theme(text = element_text(family = \"LM Sans 10\"))\n",
        "}\n",
        "\n",
        "\n",
        "# Combine plots using patchwork, remove spacing between plots, and put time axis only in the last plot\n",
        "combined_plot <- (p1 / p2 / p3 / p4 /p5) +\n",
        "  plot_layout(ncol = 1, heights = c(1, 1, 1, 1, 4)) &\n",
        "  theme(panel.spacing = unit(0, \"lines\"))\n",
        "\n",
        "# Print the combined plot\n",
        "print(combined_plot)\n",
        "\n",
        "ggsave(combined_plot,\n",
        "       filename = paste(\"combined_plot\",\"_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\"),\n",
        "       device = \"pdf\",\n",
        "       height = 10, width = 10, units = \"in\")\n",
        "\n",
        "file10 <- paste(\"combined_plot\",\"_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".pdf\", sep = \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OgPGZ1Ohbsc"
      },
      "outputs": [],
      "source": [
        "nameworkspace <- paste(\"workspace\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".Rdata\", sep = \"\")\n",
        "save.image(file=paste(\"workspace\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".Rdata\", sep = \"\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DDP7JGkJlNW"
      },
      "outputs": [],
      "source": [
        "if (timescale == \"forwards\") {\n",
        "my_files <- paste(\"results_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".zip\", sep = \"\")\n",
        "} else {\n",
        "my_files <- paste(\"results_\", data_to_forecast,\"_\", mymodel, \"_\", time_range[1],\"_\", time_range[2],\"_\", kyrs_to_forecast, \"_\", resolution,\".zip\", sep = \"\")\n",
        "}\n",
        "zip::zip(zipfile = my_files,\n",
        "        files = c(file1, file2, file3, file4, file5, file6, file7, file8, file9, file10,\n",
        "        nameworkspace\n",
        "        ))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}